{
  "hash": "989592d2fe2da01c1e6734b83530c4d1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Predictive Policing - Technical Implementation\"\nsubtitle: \"MUSA 5080 - Fall 2025\"\nauthor: \"Your Name\"\ndate: today\nformat:\n  html:\n    code-fold: show\n    code-tools: true\n    toc: true\n    toc-depth: 3\n    toc-location: left\n    theme: cosmo\n    embed-resources: true\neditor: visual\nexecute:\n  warning: false\n  message: false\n---\n\n## About This Exercise\n\nIn this exercise, you will build a spatial predictive model for burglaries using count regression and spatial features.\n\n# Learning Objectives\n\nBy the end of this exercise, you will be able to:\n\n1.  Create a fishnet grid for aggregating point-level crime data\n2.  Calculate spatial features including k-nearest neighbors and distance measures\n3.  Diagnose spatial autocorrelation using Local Moran's I\n4.  Fit and interpret Poisson and Negative Binomial regression for count data\n5.  Implement spatial cross-validation (Leave-One-Group-Out)\n6.  Compare model predictions to a Kernel Density Estimation baseline\n7.  Evaluate model performance using appropriate metrics\n\n# Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(tidyverse)      # Data manipulation\nlibrary(sf)             # Spatial operations\nlibrary(here)           # Relative file paths\nlibrary(viridis)        # Color scales\nlibrary(terra)          # Raster operations (replaces 'raster')\nlibrary(spdep)          # Spatial dependence\nlibrary(FNN)            # Fast nearest neighbors\nlibrary(MASS)           # Negative binomial regression\nlibrary(patchwork)      # Plot composition (replaces grid/gridExtra)\nlibrary(knitr)          # Tables\nlibrary(kableExtra)     # Table formatting\nlibrary(classInt)       # Classification intervals\nlibrary(here)\n\n# Spatstat split into sub-packages\nlibrary(spatstat.geom)    # Spatial geometries\nlibrary(spatstat.explore) # Spatial exploration/KDE\n\n# Set options\noptions(scipen = 999)  # No scientific notation\nset.seed(5080)         # Reproducibility\n\n# Create consistent theme for visualizations\ntheme_crime <- function(base_size = 11) {\n  theme_minimal(base_size = base_size) +\n    theme(\n      plot.title = element_text(face = \"bold\", size = base_size + 1),\n      plot.subtitle = element_text(color = \"gray30\", size = base_size - 1),\n      legend.position = \"right\",\n      panel.grid.minor = element_blank(),\n      axis.text = element_blank(),\n      axis.title = element_blank()\n    )\n}\n\n# Set as default\ntheme_set(theme_crime())\n\ncat(\"✓ All packages loaded successfully!\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ All packages loaded successfully!\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"✓ Working directory:\", getwd(), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Working directory: C:/Users/wensh/Desktop/MUSA5080/portfolio-setup-wenshaoting6-ui/week-09/lab \n```\n\n\n:::\n:::\n\n\n# Part 1: Load and Explore Data\n\n## Exercise 1.1: Load Chicago Spatial Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load police districts (used for spatial cross-validation)\npoliceDistricts <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON\") %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(District = dist_num)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `OGRGeoJSON' from data source \n  `https://data.cityofchicago.org/api/geospatial/24zt-jpfn?method=export&format=GeoJSON' \n  using driver `GeoJSON'\nSimple feature collection with 25 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -87.94011 ymin: 41.64455 xmax: -87.52414 ymax: 42.02303\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load police beats (smaller administrative units)\npoliceBeats <- \n  st_read(\"https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON\") %>%\n  st_transform('ESRI:102271') %>%\n  dplyr::select(Beat = beat_num)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `OGRGeoJSON' from data source \n  `https://data.cityofchicago.org/api/geospatial/n9it-hstw?method=export&format=GeoJSON' \n  using driver `GeoJSON'\nSimple feature collection with 277 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -87.94011 ymin: 41.64455 xmax: -87.52414 ymax: 42.02303\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load Chicago boundary\nchicagoBoundary <- \n  st_read(\"https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson\") %>%\n  st_transform('ESRI:102271')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `chicagoBoundary' from data source \n  `https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/Chapter5/chicagoBoundary.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1 feature and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -87.8367 ymin: 41.64454 xmax: -87.52414 ymax: 42.02304\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"✓ Loaded spatial boundaries\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Loaded spatial boundaries\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Police districts:\", nrow(policeDistricts), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Police districts: 25 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Police beats:\", nrow(policeBeats), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Police beats: 277 \n```\n\n\n:::\n:::\n\n\n::: callout-note\n## Coordinate Reference System\n\nWe're using `ESRI:102271` (Illinois State Plane East, NAD83, US Feet). This is appropriate for Chicago because:\n\n-   It minimizes distortion in this region\n-   Uses feet (common in US planning)\n-   Allows accurate distance calculations\n:::\n\n## Exercise 1.2: Load Burglary Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load from provided data file (downloaded from Chicago open data portal)\nburglaries <- st_read(here(\"data\", \"burglaries.shp\")) %>% \n  st_transform('ESRI:102271')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `burglaries' from data source \n  `C:\\Users\\wensh\\Desktop\\MUSA5080\\portfolio-setup-wenshaoting6-ui\\week-09\\data\\burglaries.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 7482 features and 22 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 340492 ymin: 552959.6 xmax: 367153.5 ymax: 594815.1\nProjected CRS: NAD83(HARN) / Illinois East\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check the data\ncat(\"\\n✓ Loaded burglary data\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ Loaded burglary data\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of burglaries:\", nrow(burglaries), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of burglaries: 7482 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - CRS:\", st_crs(burglaries)$input, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - CRS: ESRI:102271 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Date range:\", min(burglaries$date, na.rm = TRUE), \"to\", \n    max(burglaries$date, na.rm = TRUE), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Date range: Inf to -Inf \n```\n\n\n:::\n:::\n\n\n**Question 1.1:** How many burglaries are in the dataset? What time period does this cover? Why does the coordinate reference system matter for our spatial analysis?\n\n*Your answer here:*\n\n::: callout-warning\n## Critical Pause #1: Data Provenance\n\nBefore proceeding, consider where this data came from:\n\n**Who recorded this data?** Chicago Police Department officers and detectives\n\n**What might be missing?**\n\n-   Unreported burglaries (victims didn't call police)\n-   Incidents police chose not to record\n-   Downgraded offenses (burglary recorded as trespassing)\n-   Spatial bias (more patrol = more recorded crime)\n\n**Think About** Was there a Department of Justice investigation of CPD during this period? What did they find about data practices?\n:::\n\n## Exercise 1.3: Visualize Point Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simple point map\np1 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_sf(data = burglaries, color = \"#d62828\", size = 0.1, alpha = 0.4) +\n  labs(\n    title = \"Burglary Locations\",\n    subtitle = paste0(\"Chicago 2017, n = \", nrow(burglaries))\n  )\n\n# Density surface using modern syntax\np2 <- ggplot() + \n  geom_sf(data = chicagoBoundary, fill = \"gray95\", color = \"gray60\") +\n  geom_density_2d_filled(\n    data = data.frame(st_coordinates(burglaries)),\n    aes(X, Y),\n    alpha = 0.7,\n    bins = 8\n  ) +\n  scale_fill_viridis_d(\n    option = \"plasma\",\n    direction = -1,\n    guide = \"none\"  # Modern ggplot2 syntax (not guide = FALSE)\n  ) +\n  labs(\n    title = \"Density Surface\",\n    subtitle = \"Kernel density estimation\"\n  )\n\n# Combine plots using patchwork (modern approach)\np1 + p2 + \n  plot_annotation(\n    title = \"Spatial Distribution of Burglaries in Chicago\",\n    tag_levels = 'A'\n  )\n```\n\n::: {.cell-output-display}\n![](predictive_policing_exercise_files/figure-html/visualize-points-1.png){width=960}\n:::\n:::\n\n\n**Question 1.2:** What spatial patterns do you observe? Are burglaries evenly distributed across Chicago? Where are the highest concentrations? What might explain these patterns?\n\n*Your answer here:*\n\n# Part 2: Create Fishnet Grid\n\n## Exercise 2.1: Understanding the Fishnet\n\nA **fishnet grid** converts irregular point data into a regular grid of cells where we can:\n\n-   Aggregate counts\n-   Calculate spatial features\n-   Apply regression models\n\nThink of it as overlaying graph paper on a map.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create 500m x 500m grid\nfishnet <- st_make_grid(\n  chicagoBoundary,\n  cellsize = 500,  # 500 meters per cell\n  square = TRUE\n) %>%\n  st_sf() %>%\n  mutate(uniqueID = row_number())\n\n# Keep only cells that intersect Chicago\nfishnet <- fishnet[chicagoBoundary, ]\n\n# View basic info\ncat(\"✓ Created fishnet grid\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Created fishnet grid\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of cells:\", nrow(fishnet), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of cells: 2458 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cell size:\", 500, \"x\", 500, \"meters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cell size: 500 x 500 meters\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cell area:\", round(st_area(fishnet[1,])), \"square meters\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cell area: 250000 square meters\n```\n\n\n:::\n:::\n\n\n**Question 2.1:** Why do we use a regular grid instead of existing boundaries like neighborhoods or census tracts? What are the advantages and disadvantages of this approach?\n\n*Your answer here:*\n\n## Exercise 2.2: Aggregate Burglaries to Grid\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Spatial join: which cell contains each burglary?\nburglaries_fishnet <- st_join(burglaries, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(countBurglaries = n())\n\n# Join back to fishnet (cells with 0 burglaries will be NA)\nfishnet <- fishnet %>%\n  left_join(burglaries_fishnet, by = \"uniqueID\") %>%\n  mutate(countBurglaries = replace_na(countBurglaries, 0))\n\n# Summary statistics\ncat(\"\\nBurglary count distribution:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nBurglary count distribution:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$countBurglaries)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   2.000   3.042   5.000  40.000 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\nCells with zero burglaries:\", \n    sum(fishnet$countBurglaries == 0), \n    \"/\", nrow(fishnet),\n    \"(\", round(100 * sum(fishnet$countBurglaries == 0) / nrow(fishnet), 1), \"%)\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCells with zero burglaries: 781 / 2458 ( 31.8 %)\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize aggregated counts\nggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"Burglaries\",\n    option = \"plasma\",\n    trans = \"sqrt\",  # Square root for better visualization of skewed data\n    breaks = c(0, 1, 5, 10, 20, 40)\n  ) +\n  labs(\n    title = \"Burglary Counts by Grid Cell\",\n    subtitle = \"500m x 500m cells, Chicago 2017\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](predictive_policing_exercise_files/figure-html/visualize-fishnet-1.png){width=768}\n:::\n:::\n\n\n**Question 2.2:** What is the distribution of burglary counts across cells? Why do so many cells have zero burglaries? Is this distribution suitable for count regression? (Hint: look up overdispersion)\n\n*Your answer here:*\n\n# Part 3: Create a Kernel Density Baseline\n\nBefore building complex models, let's create a simple baseline using **Kernel Density Estimation (KDE)**.\n\n**The KDE baseline asks:** \"What if crime just happens where it happened before?\" (simple spatial smoothing, no predictors)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert burglaries to ppp (point pattern) format for spatstat\nburglaries_ppp <- as.ppp(\n  st_coordinates(burglaries),\n  W = as.owin(st_bbox(chicagoBoundary))\n)\n\n# Calculate KDE with 1km bandwidth\nkde_burglaries <- density.ppp(\n  burglaries_ppp,\n  sigma = 1000,  # 1km bandwidth\n  edge = TRUE    # Edge correction\n)\n\n# Convert to terra raster (modern approach, not raster::raster)\nkde_raster <- rast(kde_burglaries)\n\n# Extract KDE values to fishnet cells\nfishnet <- fishnet %>%\n  mutate(\n    kde_value = terra::extract(\n      kde_raster,\n      vect(fishnet),\n      fun = mean,\n      na.rm = TRUE\n    )[, 2]  # Extract just the values column\n  )\n\ncat(\"✓ Calculated KDE baseline\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated KDE baseline\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot() +\n  geom_sf(data = fishnet, aes(fill = kde_value), color = NA) +\n  geom_sf(data = chicagoBoundary, fill = NA, color = \"white\", linewidth = 1) +\n  scale_fill_viridis_c(\n    name = \"KDE Value\",\n    option = \"plasma\"\n  ) +\n  labs(\n    title = \"Kernel Density Estimation Baseline\",\n    subtitle = \"Simple spatial smoothing of burglary locations\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](predictive_policing_exercise_files/figure-html/visualize-kde-1.png){width=768}\n:::\n:::\n\n\n**Question 3.1:** How does the KDE map compare to the count map? What does KDE capture well? What does it miss?\n\n*Your answer here:*\n\n::: callout-tip\n## Why Start with KDE?\n\nThe KDE represents our **null hypothesis**: burglaries happen where they happened before, with no other information.\n\n**Your complex model must outperform this simple baseline to justify its complexity.**\n\nWe'll compare back to this at the end!\n:::\n\n# Part 4: Create Spatial Predictor Variables\n\nNow we'll create features that might help predict burglaries. We'll use \"broken windows theory\" logic: signs of disorder predict crime.\n\n## Exercise 4.1: Load 311 Abandoned Vehicle Calls\n\n\n::: {.cell}\n\n```{.r .cell-code}\nabandoned_cars <- read_csv(here(\"data/abandoned_cars_2017.csv\"))%>%\n  filter(!is.na(Latitude), !is.na(Longitude)) %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326) %>%\n  st_transform('ESRI:102271')\n\ncat(\"✓ Loaded abandoned vehicle calls\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Loaded abandoned vehicle calls\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Number of calls:\", nrow(abandoned_cars), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Number of calls: 31390 \n```\n\n\n:::\n:::\n\n\n::: callout-note\n## Data Loading Note\n\nThe data was downloaded from Chicago's Open Data Portal. You can now request an api from the Chicago portal and tap into the data there.\n\n**Consider:** How might the 311 reporting system itself be biased? Who calls 311? What neighborhoods have better 311 awareness?\n:::\n\n## Exercise 4.2: Count of Abandoned Cars per Cell\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Aggregate abandoned car calls to fishnet\nabandoned_fishnet <- st_join(abandoned_cars, fishnet, join = st_within) %>%\n  st_drop_geometry() %>%\n  group_by(uniqueID) %>%\n  summarize(abandoned_cars = n())\n\n# Join to fishnet\nfishnet <- fishnet %>%\n  left_join(abandoned_fishnet, by = \"uniqueID\") %>%\n  mutate(abandoned_cars = replace_na(abandoned_cars, 0))\n\ncat(\"Abandoned car distribution:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAbandoned car distribution:\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$abandoned_cars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    2.00    9.00   12.74   19.00  123.00 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = abandoned_cars), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"magma\") +\n  labs(title = \"Abandoned Vehicle 311 Calls\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\") +\n  labs(title = \"Burglaries\") +\n  theme_crime()\n\np1 + p2 +\n  plot_annotation(title = \"Are abandoned cars and burglaries correlated?\")\n```\n\n::: {.cell-output-display}\n![](predictive_policing_exercise_files/figure-html/visualize-abandoned-cars-1.png){width=960}\n:::\n:::\n\n\n**Question 4.1:** Do you see a visual relationship between abandoned cars and burglaries? What does this suggest?\n\n*Your answer here:*\n\n## Exercise 4.3: Nearest Neighbor Features\n\nCount in a cell is one measure. Distance to the nearest 3 abandoned cars captures local context.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate mean distance to 3 nearest abandoned cars\n# (Do this OUTSIDE of mutate to avoid sf conflicts)\n\n# Get coordinates\nfishnet_coords <- st_coordinates(st_centroid(fishnet))\nabandoned_coords <- st_coordinates(abandoned_cars)\n\n# Calculate k nearest neighbors and distances\nnn_result <- get.knnx(abandoned_coords, fishnet_coords, k = 3)\n\n# Add to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    abandoned_cars.nn = rowMeans(nn_result$nn.dist)\n  )\n\ncat(\"✓ Calculated nearest neighbor distances\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated nearest neighbor distances\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(fishnet$abandoned_cars.nn)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n   4.386   88.247  143.293  246.946  271.283 2195.753 \n```\n\n\n:::\n:::\n\n\n**Question 4.2:** What does a low value of `abandoned_cars.nn` mean? A high value? Why might this be informative?\n\n*Your answer here:*\n\n## Exercise 4.4: Distance to Hot Spots\n\nLet's identify clusters of abandoned cars using Local Moran's I, then calculate distance to these hot spots.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to calculate Local Moran's I\ncalculate_local_morans <- function(data, variable, k = 5) {\n  \n  # Create spatial weights\n  coords <- st_coordinates(st_centroid(data))\n  neighbors <- knn2nb(knearneigh(coords, k = k))\n  weights <- nb2listw(neighbors, style = \"W\", zero.policy = TRUE)\n  \n  # Calculate Local Moran's I\n  local_moran <- localmoran(data[[variable]], weights)\n  \n  # Classify clusters\n  mean_val <- mean(data[[variable]], na.rm = TRUE)\n  \n  data %>%\n    mutate(\n      local_i = local_moran[, 1],\n      p_value = local_moran[, 5],\n      is_significant = p_value < 0.05,\n      \n      moran_class = case_when(\n        !is_significant ~ \"Not Significant\",\n        local_i > 0 & .data[[variable]] > mean_val ~ \"High-High\",\n        local_i > 0 & .data[[variable]] <= mean_val ~ \"Low-Low\",\n        local_i < 0 & .data[[variable]] > mean_val ~ \"High-Low\",\n        local_i < 0 & .data[[variable]] <= mean_val ~ \"Low-High\",\n        TRUE ~ \"Not Significant\"\n      )\n    )\n}\n\n# Apply to abandoned cars\nfishnet <- calculate_local_morans(fishnet, \"abandoned_cars\", k = 5)\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualize hot spots\nggplot() +\n  geom_sf(\n    data = fishnet, \n    aes(fill = moran_class), \n    color = NA\n  ) +\n  scale_fill_manual(\n    values = c(\n      \"High-High\" = \"#d7191c\",\n      \"High-Low\" = \"#fdae61\",\n      \"Low-High\" = \"#abd9e9\",\n      \"Low-Low\" = \"#2c7bb6\",\n      \"Not Significant\" = \"gray90\"\n    ),\n    name = \"Cluster Type\"\n  ) +\n  labs(\n    title = \"Local Moran's I: Abandoned Car Clusters\",\n    subtitle = \"High-High = Hot spots of disorder\"\n  ) +\n  theme_crime()\n```\n\n::: {.cell-output-display}\n![](predictive_policing_exercise_files/figure-html/visualize-morans-1.png){width=768}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get centroids of \"High-High\" cells (hot spots)\nhotspots <- fishnet %>%\n  filter(moran_class == \"High-High\") %>%\n  st_centroid()\n\n# Calculate distance from each cell to nearest hot spot\nif (nrow(hotspots) > 0) {\n  fishnet <- fishnet %>%\n    mutate(\n      dist_to_hotspot = as.numeric(\n        st_distance(st_centroid(fishnet), hotspots %>% st_union())\n      )\n    )\n  \n  cat(\"✓ Calculated distance to abandoned car hot spots\\n\")\n  cat(\"  - Number of hot spot cells:\", nrow(hotspots), \"\\n\")\n} else {\n  fishnet <- fishnet %>%\n    mutate(dist_to_hotspot = 0)\n  cat(\"⚠ No significant hot spots found\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Calculated distance to abandoned car hot spots\n  - Number of hot spot cells: 275 \n```\n\n\n:::\n:::\n\n\n**Question 4.3:** Why might distance to a cluster of abandoned cars be more informative than distance to a single abandoned car? What does Local Moran's I tell us?\n\n*Your answer here:*\n\n::: callout-note\n**Local Moran's I** identifies:\n\n-   **High-High**: Hot spots (high values surrounded by high values)\n-   **Low-Low**: Cold spots (low values surrounded by low values)\n-   **High-Low / Low-High**: Spatial outliers\n\nThis helps us understand spatial clustering patterns.\n:::\n\n------------------------------------------------------------------------\n\n# Part 5: Join Police Districts for Cross-Validation\n\nWe'll use police districts for our spatial cross-validation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join district information to fishnet\nfishnet <- st_join(\n  fishnet,\n  policeDistricts,\n  join = st_within,\n  left = TRUE\n) %>%\n  filter(!is.na(District))  # Remove cells outside districts\n\ncat(\"✓ Joined police districts\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Joined police districts\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Districts:\", length(unique(fishnet$District)), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Districts: 22 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Cells:\", nrow(fishnet), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Cells: 1708 \n```\n\n\n:::\n:::\n\n\n# Part 6: Model Fitting\n\n## Exercise 6.1: Poisson Regression\n\nBurglary counts are count data (0, 1, 2, 3...). We'll use **Poisson regression**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create clean modeling dataset\nfishnet_model <- fishnet %>%\n  st_drop_geometry() %>%\n  dplyr::select(\n    uniqueID,\n    District,\n    countBurglaries,\n    abandoned_cars,\n    abandoned_cars.nn,\n    dist_to_hotspot\n  ) %>%\n  na.omit()  # Remove any remaining NAs\n\ncat(\"✓ Prepared modeling data\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n✓ Prepared modeling data\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Observations:\", nrow(fishnet_model), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Observations: 1708 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"  - Variables:\", ncol(fishnet_model), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Variables: 6 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Poisson regression\nmodel_poisson <- glm(\n  countBurglaries ~ abandoned_cars + abandoned_cars.nn + \n    dist_to_hotspot,\n  data = fishnet_model,\n  family = \"poisson\"\n)\n\n# Summary\nsummary(model_poisson)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = countBurglaries ~ abandoned_cars + abandoned_cars.nn + \n    dist_to_hotspot, family = \"poisson\", data = fishnet_model)\n\nCoefficients:\n                      Estimate   Std. Error z value            Pr(>|z|)    \n(Intercept)        1.976262369  0.042512701  46.486 <0.0000000000000002 ***\nabandoned_cars    -0.001360741  0.001089805  -1.249               0.212    \nabandoned_cars.nn -0.004965200  0.000198914 -24.962 <0.0000000000000002 ***\ndist_to_hotspot    0.000002874  0.000006206   0.463               0.643    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 6710.3  on 1707  degrees of freedom\nResidual deviance: 5070.6  on 1704  degrees of freedom\nAIC: 9138.9\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n**Question 6.1:** Interpret the coefficients. Which variables are significant? What do the signs (positive/negative) tell you?\n\n*Your answer here:*\n\n## Exercise 6.2: Check for Overdispersion\n\nPoisson regression assumes mean = variance. Real count data often violates this (overdispersion).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate dispersion parameter\ndispersion <- sum(residuals(model_poisson, type = \"pearson\")^2) / \n              model_poisson$df.residual\n\ncat(\"Dispersion parameter:\", round(dispersion, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDispersion parameter: 3.38 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Rule of thumb: >1.5 suggests overdispersion\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRule of thumb: >1.5 suggests overdispersion\n```\n\n\n:::\n\n```{.r .cell-code}\nif (dispersion > 1.5) {\n  cat(\"⚠ Overdispersion detected! Consider Negative Binomial model.\\n\")\n} else {\n  cat(\"✓ Dispersion looks okay for Poisson model.\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n⚠ Overdispersion detected! Consider Negative Binomial model.\n```\n\n\n:::\n:::\n\n\n## Exercise 6.3: Negative Binomial Regression\n\nIf overdispersed, use **Negative Binomial regression** (more flexible).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit Negative Binomial model\nmodel_nb <- glm.nb(\n  countBurglaries ~ abandoned_cars + abandoned_cars.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Summary\nsummary(model_nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm.nb(formula = countBurglaries ~ abandoned_cars + abandoned_cars.nn + \n    dist_to_hotspot, data = fishnet_model, init.theta = 1.603099596, \n    link = log)\n\nCoefficients:\n                      Estimate   Std. Error z value            Pr(>|z|)    \n(Intercept)        2.092907737  0.077469423  27.016 <0.0000000000000002 ***\nabandoned_cars    -0.002006352  0.002091851  -0.959               0.337    \nabandoned_cars.nn -0.005844829  0.000321389 -18.186 <0.0000000000000002 ***\ndist_to_hotspot    0.000006861  0.000011049   0.621               0.535    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(1.6031) family taken to be 1)\n\n    Null deviance: 2534.0  on 1707  degrees of freedom\nResidual deviance: 1796.6  on 1704  degrees of freedom\nAIC: 7522.6\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  1.6031 \n          Std. Err.:  0.0888 \n\n 2 x log-likelihood:  -7512.5850 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Compare AIC (lower is better)\ncat(\"\\nModel Comparison:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel Comparison:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Poisson AIC:\", round(AIC(model_poisson), 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPoisson AIC: 9138.9 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Negative Binomial AIC:\", round(AIC(model_nb), 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNegative Binomial AIC: 7522.6 \n```\n\n\n:::\n:::\n\n\n**Question 6.2:** Which model fits better (lower AIC)? What does this tell you about the data?\n\n*Your answer here:*\n\n# Part 7: Spatial Cross-Validation\n\nStandard cross-validation randomly splits data. But with spatial data, this means training on cells right next to test cells (information leakage!).\n\n**Leave-One-Group-Out (LOGO) Cross-Validation** trains on all districts except one, then tests on the held-out district.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get unique districts\ndistricts <- unique(fishnet_model$District)\ncv_results <- tibble()\n\ncat(\"Running LOGO Cross-Validation...\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning LOGO Cross-Validation...\n```\n\n\n:::\n\n```{.r .cell-code}\nfor (i in seq_along(districts)) {\n  \n  test_district <- districts[i]\n  \n  # Split data\n  train_data <- fishnet_model %>% filter(District != test_district)\n  test_data <- fishnet_model %>% filter(District == test_district)\n  \n  # Fit model on training data\n  model_cv <- glm.nb(\n    countBurglaries ~ abandoned_cars + abandoned_cars.nn + \n      dist_to_hotspot,\n    data = train_data\n  )\n  \n  # Predict on test data\n  test_data <- test_data %>%\n    mutate(\n      prediction = predict(model_cv, test_data, type = \"response\")\n    )\n  \n  # Calculate metrics\n  mae <- mean(abs(test_data$countBurglaries - test_data$prediction))\n  rmse <- sqrt(mean((test_data$countBurglaries - test_data$prediction)^2))\n  \n  # Store results\n  cv_results <- bind_rows(\n    cv_results,\n    tibble(\n      fold = i,\n      test_district = test_district,\n      n_test = nrow(test_data),\n      mae = mae,\n      rmse = rmse\n    )\n  )\n  \n  cat(\"  Fold\", i, \"/\", length(districts), \"- District\", test_district, \n      \"- MAE:\", round(mae, 2), \"\\n\")\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Fold 1 / 22 - District 5 - MAE: 2.04 \n  Fold 2 / 22 - District 4 - MAE: 1.84 \n  Fold 3 / 22 - District 22 - MAE: 2.26 \n  Fold 4 / 22 - District 6 - MAE: 3.3 \n  Fold 5 / 22 - District 8 - MAE: 2.53 \n  Fold 6 / 22 - District 7 - MAE: 3.08 \n  Fold 7 / 22 - District 3 - MAE: 6.05 \n  Fold 8 / 22 - District 2 - MAE: 2.69 \n  Fold 9 / 22 - District 9 - MAE: 2.16 \n  Fold 10 / 22 - District 10 - MAE: 2.19 \n  Fold 11 / 22 - District 1 - MAE: 1.76 \n  Fold 12 / 22 - District 12 - MAE: 3.1 \n  Fold 13 / 22 - District 15 - MAE: 2.08 \n  Fold 14 / 22 - District 11 - MAE: 3.19 \n  Fold 15 / 22 - District 18 - MAE: 2.75 \n  Fold 16 / 22 - District 25 - MAE: 2.75 \n  Fold 17 / 22 - District 14 - MAE: 2.96 \n  Fold 18 / 22 - District 19 - MAE: 2.1 \n  Fold 19 / 22 - District 16 - MAE: 2.98 \n  Fold 20 / 22 - District 17 - MAE: 2.17 \n  Fold 21 / 22 - District 20 - MAE: 2.68 \n  Fold 22 / 22 - District 24 - MAE: 2.65 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Overall results\ncat(\"\\n✓ Cross-Validation Complete\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n✓ Cross-Validation Complete\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean MAE:\", round(mean(cv_results$mae), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean MAE: 2.7 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean RMSE:\", round(mean(cv_results$rmse), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean RMSE: 3.61 \n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Show results\ncv_results %>%\n  arrange(desc(mae)) %>%\n  kable(\n    digits = 2,\n    caption = \"LOGO CV Results by District\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>LOGO CV Results by District</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:right;\"> fold </th>\n   <th style=\"text-align:left;\"> test_district </th>\n   <th style=\"text-align:right;\"> n_test </th>\n   <th style=\"text-align:right;\"> mae </th>\n   <th style=\"text-align:right;\"> rmse </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:right;\"> 7 </td>\n   <td style=\"text-align:left;\"> 3 </td>\n   <td style=\"text-align:right;\"> 43 </td>\n   <td style=\"text-align:right;\"> 6.05 </td>\n   <td style=\"text-align:right;\"> 8.08 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 4 </td>\n   <td style=\"text-align:left;\"> 6 </td>\n   <td style=\"text-align:right;\"> 63 </td>\n   <td style=\"text-align:right;\"> 3.30 </td>\n   <td style=\"text-align:right;\"> 4.75 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 14 </td>\n   <td style=\"text-align:left;\"> 11 </td>\n   <td style=\"text-align:right;\"> 43 </td>\n   <td style=\"text-align:right;\"> 3.19 </td>\n   <td style=\"text-align:right;\"> 4.09 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 12 </td>\n   <td style=\"text-align:left;\"> 12 </td>\n   <td style=\"text-align:right;\"> 73 </td>\n   <td style=\"text-align:right;\"> 3.10 </td>\n   <td style=\"text-align:right;\"> 4.62 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 6 </td>\n   <td style=\"text-align:left;\"> 7 </td>\n   <td style=\"text-align:right;\"> 52 </td>\n   <td style=\"text-align:right;\"> 3.08 </td>\n   <td style=\"text-align:right;\"> 4.07 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 19 </td>\n   <td style=\"text-align:left;\"> 16 </td>\n   <td style=\"text-align:right;\"> 129 </td>\n   <td style=\"text-align:right;\"> 2.98 </td>\n   <td style=\"text-align:right;\"> 3.48 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 17 </td>\n   <td style=\"text-align:left;\"> 14 </td>\n   <td style=\"text-align:right;\"> 46 </td>\n   <td style=\"text-align:right;\"> 2.96 </td>\n   <td style=\"text-align:right;\"> 4.24 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 16 </td>\n   <td style=\"text-align:left;\"> 25 </td>\n   <td style=\"text-align:right;\"> 85 </td>\n   <td style=\"text-align:right;\"> 2.75 </td>\n   <td style=\"text-align:right;\"> 3.62 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 15 </td>\n   <td style=\"text-align:left;\"> 18 </td>\n   <td style=\"text-align:right;\"> 30 </td>\n   <td style=\"text-align:right;\"> 2.75 </td>\n   <td style=\"text-align:right;\"> 4.15 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 8 </td>\n   <td style=\"text-align:left;\"> 2 </td>\n   <td style=\"text-align:right;\"> 56 </td>\n   <td style=\"text-align:right;\"> 2.69 </td>\n   <td style=\"text-align:right;\"> 3.60 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 21 </td>\n   <td style=\"text-align:left;\"> 20 </td>\n   <td style=\"text-align:right;\"> 30 </td>\n   <td style=\"text-align:right;\"> 2.68 </td>\n   <td style=\"text-align:right;\"> 3.11 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 22 </td>\n   <td style=\"text-align:left;\"> 24 </td>\n   <td style=\"text-align:right;\"> 41 </td>\n   <td style=\"text-align:right;\"> 2.65 </td>\n   <td style=\"text-align:right;\"> 2.98 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:left;\"> 8 </td>\n   <td style=\"text-align:right;\"> 197 </td>\n   <td style=\"text-align:right;\"> 2.53 </td>\n   <td style=\"text-align:right;\"> 3.48 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 3 </td>\n   <td style=\"text-align:left;\"> 22 </td>\n   <td style=\"text-align:right;\"> 112 </td>\n   <td style=\"text-align:right;\"> 2.26 </td>\n   <td style=\"text-align:right;\"> 2.83 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 10 </td>\n   <td style=\"text-align:left;\"> 10 </td>\n   <td style=\"text-align:right;\"> 63 </td>\n   <td style=\"text-align:right;\"> 2.19 </td>\n   <td style=\"text-align:right;\"> 3.09 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 20 </td>\n   <td style=\"text-align:left;\"> 17 </td>\n   <td style=\"text-align:right;\"> 82 </td>\n   <td style=\"text-align:right;\"> 2.17 </td>\n   <td style=\"text-align:right;\"> 2.60 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 9 </td>\n   <td style=\"text-align:left;\"> 9 </td>\n   <td style=\"text-align:right;\"> 107 </td>\n   <td style=\"text-align:right;\"> 2.16 </td>\n   <td style=\"text-align:right;\"> 2.59 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 18 </td>\n   <td style=\"text-align:left;\"> 19 </td>\n   <td style=\"text-align:right;\"> 63 </td>\n   <td style=\"text-align:right;\"> 2.10 </td>\n   <td style=\"text-align:right;\"> 2.57 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 13 </td>\n   <td style=\"text-align:left;\"> 15 </td>\n   <td style=\"text-align:right;\"> 32 </td>\n   <td style=\"text-align:right;\"> 2.08 </td>\n   <td style=\"text-align:right;\"> 2.67 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:left;\"> 5 </td>\n   <td style=\"text-align:right;\"> 98 </td>\n   <td style=\"text-align:right;\"> 2.04 </td>\n   <td style=\"text-align:right;\"> 3.09 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 2 </td>\n   <td style=\"text-align:left;\"> 4 </td>\n   <td style=\"text-align:right;\"> 235 </td>\n   <td style=\"text-align:right;\"> 1.84 </td>\n   <td style=\"text-align:right;\"> 3.69 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:right;\"> 11 </td>\n   <td style=\"text-align:left;\"> 1 </td>\n   <td style=\"text-align:right;\"> 28 </td>\n   <td style=\"text-align:right;\"> 1.76 </td>\n   <td style=\"text-align:right;\"> 2.11 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Question 7.1:** Why is spatial CV more appropriate than random CV for this problem? Which districts were hardest to predict?\n\n*Your answer here:*\n\n::: callout-note\n## Connection to Week 5\n\nRemember learning about train/test splits and cross-validation? This is a spatial version of that concept!\n\n**Why it matters:** If we can only predict well in areas we've already heavily policed, what does that tell us about the model's utility?\n:::\n\n# Part 8: Model Predictions and Comparison\n\n## Exercise 8.1: Generate Final Predictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit final model on all data\nfinal_model <- glm.nb(\n  countBurglaries ~ abandoned_cars + abandoned_cars.nn + \n    dist_to_hotspot,\n  data = fishnet_model\n)\n\n# Add predictions back to fishnet\nfishnet <- fishnet %>%\n  mutate(\n    prediction_nb = predict(final_model, fishnet_model, type = \"response\")[match(uniqueID, fishnet_model$uniqueID)]\n  )\n\n# Also add KDE predictions (normalize to same scale as counts)\nkde_sum <- sum(fishnet$kde_value, na.rm = TRUE)\ncount_sum <- sum(fishnet$countBurglaries, na.rm = TRUE)\nfishnet <- fishnet %>%\n  mutate(\n    prediction_kde = (kde_value / kde_sum) * count_sum\n  )\n```\n:::\n\n\n## Exercise 8.2: Compare Model vs. KDE Baseline\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create three maps\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = countBurglaries), color = NA) +\n  scale_fill_viridis_c(name = \"Count\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Actual Burglaries\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"Model Predictions (Neg. Binomial)\") +\n  theme_crime()\n\np3 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = prediction_kde), color = NA) +\n  scale_fill_viridis_c(name = \"Predicted\", option = \"plasma\", limits = c(0, 15)) +\n  labs(title = \"KDE Baseline Predictions\") +\n  theme_crime()\n\np1 + p2 + p3 +\n  plot_annotation(\n    title = \"Actual vs. Predicted Burglaries\",\n    subtitle = \"Does our complex model outperform simple KDE?\"\n  )\n```\n\n::: {.cell-output-display}\n![](predictive_policing_exercise_files/figure-html/compare-models-1.png){width=1152}\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate performance metrics\ncomparison <- fishnet %>%\n  st_drop_geometry() %>%\n  filter(!is.na(prediction_nb), !is.na(prediction_kde)) %>%\n  summarize(\n    model_mae = mean(abs(countBurglaries - prediction_nb)),\n    model_rmse = sqrt(mean((countBurglaries - prediction_nb)^2)),\n    kde_mae = mean(abs(countBurglaries - prediction_kde)),\n    kde_rmse = sqrt(mean((countBurglaries - prediction_kde)^2))\n  )\n\ncomparison %>%\n  pivot_longer(everything(), names_to = \"metric\", values_to = \"value\") %>%\n  separate(metric, into = c(\"approach\", \"metric\"), sep = \"_\") %>%\n  pivot_wider(names_from = metric, values_from = value) %>%\n  kable(\n    digits = 2,\n    caption = \"Model Performance Comparison\"\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\"))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Model Performance Comparison</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> approach </th>\n   <th style=\"text-align:right;\"> mae </th>\n   <th style=\"text-align:right;\"> rmse </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> model </td>\n   <td style=\"text-align:right;\"> 2.48 </td>\n   <td style=\"text-align:right;\"> 3.59 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> kde </td>\n   <td style=\"text-align:right;\"> 2.06 </td>\n   <td style=\"text-align:right;\"> 2.95 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n**Question 8.1:** Does the complex model outperform the simple KDE baseline? By how much? Is the added complexity worth it?\n\n*Your answer here:*\n\n## Exercise 9.3: Where Does the Model Work Well?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate errors\nfishnet <- fishnet %>%\n  mutate(\n    error_nb = countBurglaries - prediction_nb,\n    error_kde = countBurglaries - prediction_kde,\n    abs_error_nb = abs(error_nb),\n    abs_error_kde = abs(error_kde)\n  )\n\n# Map errors\np1 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = error_nb), color = NA) +\n  scale_fill_gradient2(\n    name = \"Error\",\n    low = \"#2166ac\", mid = \"white\", high = \"#b2182b\",\n    midpoint = 0,\n    limits = c(-10, 10)\n  ) +\n  labs(title = \"Model Errors (Actual - Predicted)\") +\n  theme_crime()\n\np2 <- ggplot() +\n  geom_sf(data = fishnet, aes(fill = abs_error_nb), color = NA) +\n  scale_fill_viridis_c(name = \"Abs. Error\", option = \"magma\") +\n  labs(title = \"Absolute Model Errors\") +\n  theme_crime()\n\np1 + p2\n```\n\n::: {.cell-output-display}\n![](predictive_policing_exercise_files/figure-html/prediction-errors-1.png){width=960}\n:::\n:::\n\n\n**Question 9.2:** Where does the model make the biggest errors? Are there spatial patterns in the errors? What might this reveal?\n\n*Your answer here:*\n\n# Part 10: Summary Statistics and Tables\n\n## Exercise 10.1: Model Summary Table\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create nice summary table\nmodel_summary <- broom::tidy(final_model, exponentiate = TRUE) %>%\n  mutate(\n    across(where(is.numeric), ~round(., 3))\n  )\n\nmodel_summary %>%\n  kable(\n    caption = \"Final Negative Binomial Model Coefficients (Exponentiated)\",\n    col.names = c(\"Variable\", \"Rate Ratio\", \"Std. Error\", \"Z\", \"P-Value\")\n  ) %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\")) %>%\n  footnote(\n    general = \"Rate ratios > 1 indicate positive association with burglary counts.\"\n  )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover\" style=\"margin-left: auto; margin-right: auto;border-bottom: 0;\">\n<caption>Final Negative Binomial Model Coefficients (Exponentiated)</caption>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Variable </th>\n   <th style=\"text-align:right;\"> Rate Ratio </th>\n   <th style=\"text-align:right;\"> Std. Error </th>\n   <th style=\"text-align:right;\"> Z </th>\n   <th style=\"text-align:right;\"> P-Value </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 8.108 </td>\n   <td style=\"text-align:right;\"> 0.077 </td>\n   <td style=\"text-align:right;\"> 27.016 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> abandoned_cars </td>\n   <td style=\"text-align:right;\"> 0.998 </td>\n   <td style=\"text-align:right;\"> 0.002 </td>\n   <td style=\"text-align:right;\"> -0.959 </td>\n   <td style=\"text-align:right;\"> 0.337 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> abandoned_cars.nn </td>\n   <td style=\"text-align:right;\"> 0.994 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> -18.186 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> dist_to_hotspot </td>\n   <td style=\"text-align:right;\"> 1.000 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> 0.621 </td>\n   <td style=\"text-align:right;\"> 0.535 </td>\n  </tr>\n</tbody>\n<tfoot>\n<tr><td style=\"padding: 0; \" colspan=\"100%\"><span style=\"font-style: italic;\">Note: </span></td></tr>\n<tr><td style=\"padding: 0; \" colspan=\"100%\">\n<sup></sup> Rate ratios &gt; 1 indicate positive association with burglary counts.</td></tr>\n</tfoot>\n</table>\n\n`````\n:::\n:::\n\n\n## Exercise 10.2: Key Findings Summary\n\nBased on your analysis, complete this summary:\n\n**Technical Performance:**\n\n-   Cross-validation MAE: 2.7\n-   Model vs. KDE: \\[Which performed better?\\]\n-   Most predictive variable: \\[Which had largest effect?\\]\n\n**Spatial Patterns:**\n\n-   Burglaries are \\[evenly distributed / clustered\\]\n-   Hot spots are located in \\[describe\\]\n-   Model errors show \\[random / systematic\\] patterns\n\n**Model Limitations:**\n\n-   Overdispersion: \\[Yes/No\\]\n-   Spatial autocorrelation in residuals: \\[Test this!\\]\n-   Cells with zero counts: \\[What % of data?\\]\n\n# Conclusion and Next Steps\n\n::: callout-important\n## What You've Accomplished\n\nYou've successfully built a spatial predictive model for burglaries using:\n\n✓ Fishnet aggregation\\\n✓ Spatial features (counts, distances, nearest neighbors)\\\n✓ Spatial autocorrelation diagnostics (Local Moran's I)\\\n✓ Count regression (Poisson and Negative Binomial)\\\n✓ Spatial cross-validation (LOGO)\\\n✓ Comparison to baseline (KDE)\n:::\n\n::::::::::\n",
    "supporting": [
      "predictive_policing_exercise_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}