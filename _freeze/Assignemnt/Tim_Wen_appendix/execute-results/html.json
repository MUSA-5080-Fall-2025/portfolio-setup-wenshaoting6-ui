{
  "hash": "fb2a6f455487e76d617b4811f553d8a4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Technical Appendix\"\nformat: \n  html:\n    toc: true\n    toc-location: left\n    code-fold: show\n    theme: cosmo\n---\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\n载入程序包：'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\n\nLinking to GEOS 3.13.1, GDAL 3.11.0, PROJ 9.6.0; sf_use_s2() is TRUE\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\nhere() starts at C:/Users/wensh/Desktop/MUSA5080/portfolio-setup-wenshaoting6-ui\n\nData (c) OpenStreetMap contributors, ODbL 1.0. https://www.openstreetmap.org/copyright.\nCheck the package website, https://docs.ropensci.org/osmextract/, for more details.\n\n载入需要的程序包：spatstat.data\n\n载入需要的程序包：spatstat.univar\n\nspatstat.univar 3.1-4\n\nspatstat.geom 3.6-0\n\n\n载入程序包：'spatstat.geom'\n\n\nThe following object is masked from 'package:patchwork':\n\n    area\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\n载入需要的程序包：spatstat.random\n\nspatstat.random 3.4-2\n\n载入需要的程序包：spatstat.explore\n\n载入需要的程序包：nlme\n\n\n载入程序包：'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\n\nspatstat.explore 3.5-3\n\n载入需要的程序包：spatstat.model\n\n载入需要的程序包：rpart\n\nspatstat.model 3.4-2\n\n载入需要的程序包：spatstat.linnet\n\nspatstat.linnet 3.3-2\n\n\nspatstat 3.4-1 \nFor an introduction to spatstat, type 'beginner' \n\n\nterra 1.8.60\n\n\n载入程序包：'terra'\n\n\nThe following objects are masked from 'package:spatstat.geom':\n\n    area, delaunay, is.empty, rescale, rotate, shift, where.max,\n    where.min\n\n\nThe following object is masked from 'package:patchwork':\n\n    area\n\n\nThe following object is masked from 'package:tigris':\n\n    blocks\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following object is masked from 'package:knitr':\n\n    spin\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\n\n载入程序包：'jsonlite'\n\n\nThe following object is masked from 'package:purrr':\n\n    flatten\n\n\n\nPlease cite as: \n\n\n Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables.\n\n R package version 5.2.3. https://CRAN.R-project.org/package=stargazer \n\n\n载入需要的程序包：carData\n\n\n载入程序包：'car'\n\n\nThe following object is masked from 'package:spatstat.model':\n\n    bc\n\n\nThe following object is masked from 'package:spatstat.geom':\n\n    ellipse\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n\n载入需要的程序包：zoo\n\n\n载入程序包：'zoo'\n\n\nThe following object is masked from 'package:terra':\n\n    time<-\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n```\n\n\n:::\n:::\n\n\n# PHASE 1: DATA PREPARATION\n\n## 1.1 Load and Philadelphia house sales data\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load Philly Property Sales data\nphl_sales <- read_csv(here(\"data\", \"raw\", \"opa_properties_public.csv\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 583776 Columns: 79\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (38): basements, beginning_point, book_and_page, building_code, buildin...\ndbl  (31): objectid, category_code, census_tract, depth, exempt_building, ex...\nlgl   (7): cross_reference, date_exterior_condition, mailing_address_2, mark...\ndttm  (3): assessment_date, recording_date, sale_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n### Filter to residential properties, 2023-2024 sales\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check data types\n# glimpse(phl_sales)\n\nphl_sales_res_23_24 <- phl_sales |>\n  filter(\n    category_code == 1, # Residential\n    year(sale_date) %in% c(2023, 2024), # 2023-24 sales\n    !is.na(category_code) & !is.na(sale_date) # Handle nulls\n  )\n```\n:::\n\n\n### Remove obvious errors\n\n::: {.cell}\n\n```{.r .cell-code}\nphl_sales_clean <- phl_sales_res_23_24 |>\n  filter(\n    # Some sale_price are unrealistically too low ($0, $1 etc.)\n    sale_price >= 10000,\n    # Exclude homes with 0 bathrooms\n    number_of_bathrooms > 0,\n    # Some areas are unrealistically low (0, 1, etc.)\n    total_area > 1,\n    # Some 0's remain in total_liveable_area after first area filter\n    total_livable_area > 0,\n    # Filter our unrealistic year built\n    year_built >= 1750\n    ) \n```\n:::\n\n\n### Handle missing values\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check how many features have NA values\n# sum(is.na(phl_sales_clean$number_of_bedrooms))\n# sum(is.na(phl_sales_clean$number_of_bathrooms))\n# sum(is.na(phl_sales_clean$total_livable_area))\n# sum(is.na(phl_sales_clean$year_built))\n\n# Remove the 2 observations with NA values for number of bedrooms\nphl_sales_clean <- phl_sales_clean |>\n  filter(\n    !is.na(number_of_bedrooms)\n  )\n```\n:::\n\n\n### Preliminary Feature Engineering: Age = sale date - year built\n\n::: {.cell}\n\n```{.r .cell-code}\nphl_sales_clean <- phl_sales_clean |>\n  mutate(\n    sale_year = year(sale_date),\n    age = sale_year - year_built\n  )\n```\n:::\n\n\n### Document all cleaning decisions\n\n\n- Our methodology for cleaning the Philadelphia home sales data is to focus on the features used in our model. As a group, we decided on the following independent variables to consider in our data exploration and model building to be: number of bathrooms, number of bedrooms, total livable area, and year built. We recognize that there is some risk of collinearity between these structural features, which will later be monitored and addressed if needed in the model building stage. Additionally, we also had to clean the sales price column since this is the variable we aim to predict in our model.\n\n\n- Filter for only **residential properties** & **sales made in 2023-24** (per instructions).\n\n\n- Filter for **realistic sales price** >= $10,000.\n\n\n- Filter for houses with **at least 1 bathroom**. We will keep observations where **number of bedrooms = 0** as this likely signifies a studio apartment. However, it is not feasible for homes to have zero bathrooms, so we will enforce a constraint that a home must have at least 1 bathroom to preserve data integrity.\n\n\n- Filter for **realistic total area** > 1 sq ft & **realistic total livable area** > 0 sq ft.\n\n\n- Filter for **year built** >= 1750 (some homes were built in year 0).\n\n\n- **Handle missing values:** We removed any missing values in our dependent variable of sales price, since it is crucial we have a true and accurate measure for prediction. We also checked which of our predictor variables had NA values after filtering. Only number of bedrooms had 2 remaining NA values. The rest had no NA values. To remedy this, we will remove the 2 observations from our data. Note, if there was substantial missing values in our predictors, we could use strategies such as imputing the NA values with the mean or median to use when building our model. \n\n\n- **Preliminary feature engineering:** Rather than using year built in our Automated Valuation Model, it makes more sense to create a new variable **age** that is equal to the sale date minus the year built. The **age** variable is often easier to interpret in exploratory plots with the newer houses appearing on the left and older ones on the right. This is primarily a stylistic preference: the overall pattern of the data will remain the same but mirrored.\n\n\n## 1.2 Load Secondary Data\n\n### Census\n\nPurpose: Pull demographic and housing data at the census tract level for Philadelphia from the 2023 5-year ACS. This data will provide predictors for neighborhood characteristics in our modeling.\n\nVariables Collected:\n\nMedian household income (B19013)\n\nPercentage of family households (B11001)\n\nEducation attainment: percent of population 25+ with a bachelor’s degree or higher (B15003)\n\nHousing vacancy rate (B25002)\n\nRacial composition: percent white (B02001)\n\n\n\n#### Load Philly Census Data from Previously Retrieved Files\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Relative to project root\ncensus_path <- here(\"data\", \"Philly Census\")\n\ncensus_csv_path <- file.path(census_path, \"philly_tract_metrics.csv\")\ncensus_shp_path <- file.path(census_path, \"philly_tract.shp\")\n\n# Csv with census tract Geo IDs and metrics\nphilly_censustract <- read_csv(census_csv_path, show_col_types = FALSE)\n\n# Shp File including geometry\nphilly_tract_sf <- st_read(census_shp_path, quiet = TRUE)\n```\n:::\n\n\n#### Observe Summary Statistics from target metrics.x\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnumeric_vars <- c(\"median_income\", \"pct_white\", \"pct_bachelors\", \"pct_vacant\")\nphilly_censustract %>%\n  select(all_of(numeric_vars)) %>%\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n median_income      pct_white      pct_bachelors      pct_vacant     \n Min.   : 13721   Min.   : 0.000   Min.   : 1.504   Min.   :  0.000  \n 1st Qu.: 42469   1st Qu.: 8.826   1st Qu.:16.094   1st Qu.:  5.366  \n Median : 60817   Median :34.740   Median :28.426   Median :  8.516  \n Mean   : 66877   Mean   :37.944   Mean   :36.325   Mean   :  9.844  \n 3rd Qu.: 85298   3rd Qu.:64.202   3rd Qu.:55.345   3rd Qu.: 12.801  \n Max.   :192727   Max.   :95.513   Max.   :96.632   Max.   :100.000  \n NA's   :27       NA's   :17       NA's   :17       NA's   :19       \n```\n\n\n:::\n:::\n\nA quick check of the census variables reveals some missing values and lower than epected values in median income. We will note this information but retain the missing values for now to maintain the full pitcure of census blocks.\n\n\n### Cleaning Methodology (Census)\n\nMedian income: Selected only the estimate column and renamed it for clarity.\n\nHousehold composition: Pivoted ACS table to wide format, then calculated total households and family households.\n\nEducation: Pivoted to wide format, summed relevant categories to compute percent of population with a bachelor’s degree or higher.\n\nVacancy: Pivoted to wide format, calculated percent of homes vacant (vacant_units / total_units * 100).\n\nRacial composition: Pivoted to wide format, computed percent white.\n\nMerging: Combined all datasets by GEOID to create a single dataframe philly_blockgroup with all variables.\n\nGeometry: Pulled census tract shapefiles with ACS geometry and merged with philly_blockgroup to create philly_bg_map.\n\n### Neighborhood (Polygon)\n\nReading in Philadelphia Neighborhoods as a shp object. This will allow us to aggregate data on neighborhoods to identify catagorical metrics.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nneighborhood_folder <- here(\"data\", \"philadelphia-neighborhoods\")\nneighborhood_path   <- file.path(neighborhood_folder, \"philadelphia-neighborhoods.shp\")\n\n# Read the shapefile\nphilly_neighborhoods <- st_read(neighborhood_path, quiet = TRUE)\n\nhead(philly_neighborhoods)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 6 features and 5 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -75.23049 ymin: 39.98491 xmax: -75.0156 ymax: 40.11269\nGeodetic CRS:  WGS 84\n             NAME         LISTNAME         MAPNAME Shape_Leng Shape_Area\n1      BRIDESBURG       Bridesburg      Bridesburg   27814.55   44586264\n2       BUSTLETON        Bustleton       Bustleton   48868.46  114050424\n3      CEDARBROOK       Cedarbrook      Cedarbrook   20021.42   24871745\n4   CHESTNUT_HILL    Chestnut Hill   Chestnut Hill   56394.30   79664975\n5      EAST_FALLS       East Falls      East Falls   27400.78   40576888\n6 MOUNT_AIRY_EAST Mount Airy, East East Mount Airy   28845.55   43152470\n                        geometry\n1 POLYGON ((-75.06773 40.0054...\n2 POLYGON ((-75.0156 40.09487...\n3 POLYGON ((-75.18848 40.0727...\n4 POLYGON ((-75.21221 40.0860...\n5 POLYGON ((-75.18476 40.0282...\n6 POLYGON ((-75.18087 40.0432...\n```\n\n\n:::\n:::\n\n\n\n### Commercial and office points of interests (Amenities)(alternative in the next section if you do not want to download pbf data)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# downloading osm data from geofabrik:https://download.geofabrik.de/north-america/us-northeast.html\n\n#input_pbf <- \"the pdf file downloaded from the link above\"\n\n\n# get boundary of Philadelphia County\npa_counties <- counties(state = \"PA\", year = 2023)\n\n# Filter to Philadelphia County\nphilly_boundary <- subset(pa_counties, NAME == \"Philadelphia\")\n\n# read the full OSM PBF (you can select layer types like points, lines, polygons)\npoi <- oe_read(input_pbf, \n                       boundary = philly_boundary, \n                       boundary_type = \"clipsrc\", \n                       layer = \"points\")  # or \"lines\" / \"multipolygons\"\n\n\nkeywords <- c(\"shop\",\"amenity\",\"office\",\"historic\",\"tourism\",\"healthcare\",\n              \"building\",\"leisure\")\npattern <- paste0(keywords, collapse = \"|\")\n\n# ==== Filter by 'other_tags' ====\nif (\"other_tags\" %in% names(poi)) {\n  poi$other_tags <- iconv(as.character(poi$other_tags), from = \"\", to = \"UTF-8\", sub = \"\")\n  poi$other_tags[is.na(poi$other_tags)] <- \"\"\n  \n  poi_filtered <- poi %>%\n    filter(grepl(pattern, other_tags, ignore.case = TRUE))\n  \n  cat(\"filtered POIs found:\", nrow(poi_filtered), \"of\", nrow(poi), \"\\n\")\n  \n} \n```\n:::\n\n\n### Alternative: filtered POI if you donot want to download osm data\n\n::: {.cell}\n\n```{.r .cell-code}\npoi_path <- here(\"data\", \"filtered poi\")\npoi_shp_path=file.path(poi_path, \"philadelphia_poi_filtered.shp\")\npoi=st_read(poi_shp_path)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `philadelphia_poi_filtered' from data source \n  `C:\\Users\\wensh\\Desktop\\MUSA5080\\portfolio-setup-wenshaoting6-ui\\data\\filtered poi\\philadelphia_poi_filtered.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 11161 features and 10 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -75.27472 ymin: 39.87383 xmax: -74.95777 ymax: 40.13445\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n:::\n\n\n### Kernel Density Rasters (Economic activities density)\nInstead of using distance to CBD, we extracted commercial and office points of interests from OpenStreetMap (OSM), and we opreate a Kernel Density Estimation (KDE) with a bandwidth of 300 meters. By doing that, we manage to get a surface of density of economic activities across the whole city. The higher the KDE value is, the more economic activities it will be, implying a higher likelyhood of the area as a city centers.\n\nThere are several benefits using this approach compared to distance to CBD. First, with the development of suburbanization, even within the context of Philadelphia County, there is still a shift from monocentric model to polycentric model, meaning there multiple centers/subcenters. Using one CBD fail to capture these subcenters, which may also influence housing price. Second, CBD is an area rather than a point, distance method fail to capture this while the continuous surface computed by KDE would have a value of economic activities across the whole city. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get boundary of Philadelphia County\npa_counties <- counties(state = \"PA\", year = 2023)\n\n# Filter to Philadelphia County\nphilly_boundary <- subset(pa_counties, NAME == \"Philadelphia\")\n\nphilly_boundary <- st_transform(philly_boundary, 3364)  \npoi <- st_transform(poi, 3364)\n# ==== Prepare point pattern ====\n# Convert sf points to spatstat ppp object\nwin <- as.owin(st_union(philly_boundary))  # window from county boundary\ncoords <- st_coordinates(poi)\npp <- ppp(x = coords[,1], y = coords[,2], window = win)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: data contain duplicated points\n```\n\n\n:::\n\n```{.r .cell-code}\n# ==== Run Kernel Density Estimation ====\n# Sigma = bandwidth in map units (here, meters)\ndensity_map <- density.ppp(pp, sigma = 300* 3.28084, edge = TRUE, at = \"pixels\",eps = c(100, 100))\n\n# ==== Convert to raster ====\nr_Economic <- rast(density_map)\ncrs(r_Economic) <- st_crs(philly_boundary)$proj4string\nr_Economic <- mask(r_Economic, vect(philly_boundary))\n```\n:::\n\n\n### Education\n\nWe used two datasets from OpenDataPhilly.com to identify schools geolocation and populated the metrics off Attendance percent and Withdrawal volumes from those schools.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Relative to project root\neducation_path <- here(\"data\", \"Education\")\n\neducation_csv_path <- file.path(education_path, \"philadelphia_schools.csv\")\neducation_shp_path <- file.path(education_path, \"Schools Shape\", \"Schools.shp\")\n\n# Csv with School Names and metrics\nphilly_schools <- read_csv(education_csv_path, show_col_types = FALSE)\n\n# Shp File including geometry\nphilly_schools_sf <- st_read(education_shp_path, quiet = TRUE)\n```\n:::\n\n\nWe joined the csv file containing the metrics with the shp file containing geoloaction.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Joining Schools csv metrics to shp file. Joined on 'location_i' (shp) and 'School_code (csv)\n# Keeping metrics for Attendance and Withdrawals\n\n# Select relevant metrics from CSV\nschool_metrics <- philly_schools %>%\n  select(School_code, Attendance, Withdrawals) %>%\n  mutate(School_code = as.character(School_code))\n\nphilly_schools_sf <- philly_schools_sf %>%\n  left_join(school_metrics,\n            by = c(\"location_i\" = \"School_code\"))\n```\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nphilly_schools_sf_clean <- philly_schools_sf %>%\n  filter(!is.na(Attendance) & !is.na(Withdrawals))\n```\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(philly_schools_sf_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"aun\"         \"school_num\"  \"location_i\"  \"school_nam\"  \"school_n_1\" \n [6] \"street_add\"  \"zip_code\"    \"phone_numb\"  \"grade_leve\"  \"grade_org\"  \n[11] \"enrollment\"  \"type\"        \"type_speci\"  \"objectid\"    \"Attendance\" \n[16] \"Withdrawals\" \"geometry\"   \n```\n\n\n:::\n\n```{.r .cell-code}\nnrow(philly_schools_sf_clean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 204\n```\n\n\n:::\n:::\n\nOnce joined, we dropped rows that did not have values in Attendance and Withdrawal. This resulted in 204 public schools and their metrics located in Philadelphia City Limits.\n\n###Tree density\nLocation of trees data was extracted from Opendata Philly. A Kernel Density Estimation was used to estimate the density of trees. The higher the value is, the more trees there will be in this (and surronding) cell\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_path <- here(\"data\", \"ppr_tree_inventory_2024\")\n\ntree_shp_path <- file.path(tree_path, \"ppr_tree_inventory_2024.shp\")\n\n\ntrees=st_read(tree_shp_path)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `ppr_tree_inventory_2024' from data source \n  `C:\\Users\\wensh\\Desktop\\MUSA5080\\portfolio-setup-wenshaoting6-ui\\data\\ppr_tree_inventory_2024\\ppr_tree_inventory_2024.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 151713 features and 6 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -8380434 ymin: 4847791 xmax: -8344373 ymax: 4885938\nProjected CRS: WGS 84 / Pseudo-Mercator\n```\n\n\n:::\n\n```{.r .cell-code}\ntrees=st_transform(trees,3364)\n\n# Convert sf points to spatstat ppp object\ncoords_trees <- st_coordinates(trees)\npp_trees <- ppp(x = coords_trees[,1], y = coords_trees[,2], window = win)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: 355 points were rejected as lying outside the specified window\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: data contain duplicated points\n```\n\n\n:::\n\n```{.r .cell-code}\n# ==== Run Kernel Density Estimation ====\n# Sigma = bandwidth in map units (here, meters)\ndensity_map_trees <- density.ppp(pp_trees, edge = TRUE, at = \"pixels\",eps = c(100, 100))\n\n# ==== Convert to raster ====\nr_trees <- rast(density_map_trees)\ncrs(r_trees) <- st_crs(philly_boundary)$proj4string\nr_trees <- mask(r_trees, vect(philly_boundary))  # mask to county boundary\n```\n:::\n\n\n### Joining data together\nFirst, since commercial and office POI and trees are point data, and the more they cluster the higher the housing price will be. As a result, we use Kernel Density method to estimate the density of them. Value of the cell was assign to the point (housing prices), if the point falls within it. \n\nSecond, as census tracts and neighborhood are polygon data, a st_within spatial join was used to join them with housing data. Values from polygon data will assign to the points when points fall within it.  \n\n::: {.cell}\n\n```{.r .cell-code}\n# Geometry - Cenus Data Merge\nphilly_tract_sf$GEOID=as.numeric(philly_tract_sf$GEOID)\nphilly_tract_map <- philly_tract_sf %>%\n  left_join(philly_censustract, by = \"GEOID\")\n\n#convert housing prices data into point data\nphl_sales_clean_sf = phl_sales_clean%>%\n  mutate(geometry = st_as_sfc(shape)) %>%   # parse WKT into geometry\n  st_as_sf(crs = 2272)  \n#convert and match the crs\nphilly_schools_sf_clean=philly_schools_sf_clean%>%\n  st_transform(2272)\nphilly_neighborhoods=philly_neighborhoods%>%\n  st_transform(2272)\nphilly_tract_map=philly_tract_map%>%\n  st_transform(2272)\n#merge them together\nphl_sales_clean_sf_final=phl_sales_clean_sf%>%\n  st_join(philly_tract_map,join=st_within)%>%\n  st_join(philly_neighborhoods,join = st_within)\nphl_sales_clean_sf_final <- st_transform(phl_sales_clean_sf_final, crs = st_crs(r_trees))\nphl_sales_clean_sf_final$EconKDE <- raster::extract(r_Economic,phl_sales_clean_sf_final)\nphl_sales_clean_sf_final$TreeKDE <- raster::extract(r_trees, phl_sales_clean_sf_final)  \nphl_sales_clean_sf_final=phl_sales_clean_sf_final%>%\n  st_transform(2272)\n```\n:::\n\n\n\n### Summary table before and after dimensions\n\n::: {.cell}\n\n```{.r .cell-code}\nbefore_after_summary <- data.frame(\n  Stage = c(\"Raw Data\", \n            \"After Residential Filter (2023–24)\", \n            \"After Removing Errors & NAs\", \n            \"After Spatial Joins & Final Cleaning\"),\n  Rows = c(nrow(phl_sales),\n           nrow(phl_sales_res_23_24),\n           nrow(phl_sales_clean),\n           nrow(phl_sales_clean_sf_final)),\n  Columns = c(ncol(phl_sales),\n              ncol(phl_sales_res_23_24),\n              ncol(phl_sales_clean),\n              ncol(phl_sales_clean_sf_final))\n)\n\nknitr::kable(before_after_summary, caption = \"Data dimensions before and after cleaning\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Data dimensions before and after cleaning\n\n|Stage                                |   Rows| Columns|\n|:------------------------------------|------:|-------:|\n|Raw Data                             | 583776|      79|\n|After Residential Filter (2023–24)   |  34567|      79|\n|After Removing Errors & NAs          |  22034|      81|\n|After Spatial Joins & Final Cleaning |  22034|     106|\n\n\n:::\n:::\n\n\n\n\n\n# PHASE 2: EXPLORATORY DATA ANALYSIS\n\n### Distribution of sale prices (histogram)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the median / mean to plot\nprice_median <- median(phl_sales_clean$sale_price, na.rm = TRUE)\n\nggplot(phl_sales_clean, aes(sale_price)) +\n  geom_histogram(bins = 60, fill = \"darkseagreen3\", color = \"black\") +\n  geom_vline(xintercept = price_median, linetype = 5) +\n  annotate(\"text\",\n           x = price_median, \n           y = 6300, \n           label = \"Median\",\n           hjust = -0.2, \n           color = \"black\", \n           size = 3) +\n  scale_x_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices\",\n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Sale Price\",\n       y = \"Count\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:** The histogram plot above shows the full distribution of home sale prices for residential properties in 2023-2024 from our cleaned dataset. The data is extremely right-skewed, highlighting a majority of prices under \\$500,000 with a long tail of more expensive homes thereafter. The main issue with the extreme outliers of home prices exceeding \\$5 million that make the visibility of this plot hard to interpret. Also, there are major gaps at higher sales prices as we see the data become more spread out, further indicating the presence of outliers. Therefore, to remedy this, we will plot a second histogram of the price distribution, excluding the top 5% of sales prices from the original cleaned dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create new df, filtering out the top 5% of house prices (outliers)\nprice_95_perc <- quantile(phl_sales_clean$sale_price, 0.95, na.rm = TRUE)\ndf_95_exclude <- filter(phl_sales_clean, sale_price <= price_95_perc)\n\n# Calculate the median / mean to plot from trimmed distribution\nprice_median_95_exc <- median(df_95_exclude$sale_price, na.rm = TRUE)\nprice_mean_95_exc <- mean(df_95_exclude$sale_price, na.rm = TRUE)\n\n\nggplot(df_95_exclude, aes(sale_price)) +\n  geom_histogram(bins = 20, fill = \"darkseagreen3\", color = \"black\") +\n  geom_vline(xintercept = price_mean_95_exc, linetype = 5) +\n  geom_vline(xintercept = price_median_95_exc, linetype = 5) +\n  annotate(\"text\",\n           x = price_mean_95_exc,\n           y = 2400,\n           label = \"Mean\", \n           hjust = - 0.1, \n           color = \"black\", \n           size = 3) +\n  annotate(\"text\",\n           x = price_median_95_exc, \n           y = 2450, \n           label = \"Median\",\n           hjust = 1.25, \n           color = \"black\", \n           size = 3) +\n  scale_x_continuous(labels = label_dollar()) +\n  labs(\n    title = \"Distribution of Home Sale Prices\",\n    subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n    caption = \"Histogram and median/mean statistics were computed on filtered sample (sale price ≤ 95th percentile) for better visibility.\",\n    x = \"Sale Price\",\n    y = \"Count\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  ) \n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:** In this revised histogram, we get a much better sense of how the sales prices are distributed without the presence of extreme outliers. As we saw before, the data is definitely right-skewed since the median (\\$235,250) is less than the mean (\\$322,231) even when removing large outliers from the top 5% of the distribution. We can visualize that the standard housing market in Philadelphia from 2023-2024 ranges between \\$0 and \\$800,000. The distribution has a single peak around \\$200,000, indicating that it is unimodal with a typical (or most common) home sale price in the realm of \\$150,000 to \\$250,000. This is an indication that it may be best to omit these significant outliers from our dataset when building our model for home sale price prediction. The homes on the higher end of the sale price distribution are determined by a combination of structural features (such total livable area) and spatial features (such as nearby city centers) that drive up the prices of these homes. The goal of this study is to determine what features, both structural and spatial, are significant in predicting home sale prices in Philadelphia and create an accurate model to help policy makers in valuating property tax assessments.\n\n### Geographic distribution of sales price by tract\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tmap)\n\nprice_95_perc <- quantile(phl_sales_clean$sale_price, 0.95, na.rm = TRUE)\ndf_95_exclude <- phl_sales_clean %>%\n  filter(sale_price <= price_95_perc)\n\ndf_95_exclude_sf <- df_95_exclude %>%\n  mutate(geometry = st_as_sfc(shape)) %>%\n  st_as_sf(crs = 2272) %>%\n  st_join(philly_tract_map, join = st_within)\n\ntract_price_summary <- df_95_exclude_sf %>%\n  st_drop_geometry() %>%\n  group_by(GEOID) %>%\n  summarize(median_price = median(sale_price, na.rm = TRUE))\n\nphilly_price_map <- philly_tract_map %>%\n  left_join(tract_price_summary, by = \"GEOID\")\n\ntmap_mode(\"plot\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nℹ tmap mode set to \"plot\".\n```\n\n\n:::\n\n```{.r .cell-code}\nprice_map <- tm_shape(philly_price_map) +\n  tm_polygons(\n    col = \"median_price\",\n    style = \"quantile\",\n    n = 5,\n    palette = \"YlGnBu\",\n    title = \"Median Sale Price (≤ 95th Percentile)\"\n  ) +\n  tm_layout(\n    main.title = \"Median Home Sale Prices by Census Tract (Filtered to ≤ 95th Percentile)\",\n    main.title.position = \"center\",\n    main.title.fontface = \"bold\",\n    outer.margins = c(0.10, 0.02, 0.02, 0.02),\n    legend.outside = TRUE\n  ) +\n  tm_shape(df_95_exclude_sf) +\n  tm_dots(\n    col = \"gray30\",\n    alpha = 0.3,\n    size = 0.02,\n    legend.show = FALSE\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3->v4] `tm_polygons()`: instead of `style = \"quantile\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'n', 'palette' (rename to 'values') to\n  'tm_scale_intervals(<HERE>)'[v3->v4] `tm_polygons()`: use 'fill' for the fill color of polygons/symbols\n(instead of 'col'), and 'col' for the outlines (instead of 'border.col').[v3->v4] `tm_polygons()`: migrate the argument(s) related to the legend of the\nvisual variable `fill` namely 'title' to 'fill.legend = tm_legend(<HERE>)'[v3->v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`[v3->v4] `tm_dots()`: use `fill_alpha` instead of `alpha`.[v3->v4] `tm_dots()`: use `fill.legend = tm_legend_hide()` instead of\n`legend.show = FALSE`.[tm_dots()] Argument `legend.show` unknown.\n```\n\n\n:::\n\n```{.r .cell-code}\nprice_map\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"YlGnBu\" is named\n\"brewer.yl_gn_bu\"\nMultiple palettes called \"yl_gn_bu\" found: \"brewer.yl_gn_bu\", \"matplotlib.yl_gn_bu\". The first one, \"brewer.yl_gn_bu\", is returned.\n\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:**\n\nThis visualization shows clear spatial clustering of home prices in Philadelphia when looking at the typical market excluding outliers. Higher median prices are concentrated in Center City, University City, and select neighborhoods in South Philadelphia and Northwest Philadelphia. This supports our need to include additional predictors to account amenity density and economic activity.\n\n### Distribution of median income by neighborhood\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncensus_points <- st_centroid(philly_tract_map)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: st_centroid assumes attributes are constant over geometries\n```\n\n\n:::\n\n```{.r .cell-code}\npoints_joined <- st_join(census_points, philly_neighborhoods)\n\nmean_income_by_neighborhood <- points_joined %>%\n  st_drop_geometry() %>%\n  group_by(MAPNAME) %>%\n  summarise(mean_income = mean(median_income, na.rm = TRUE))\n\nphilly_neighborhood_income <- philly_neighborhoods %>%\n  left_join(mean_income_by_neighborhood, by = \"MAPNAME\")\n\nlibrary(tmap)\n\ntmap_mode(\"plot\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nℹ tmap mode set to \"plot\".\n```\n\n\n:::\n\n```{.r .cell-code}\nneighborhood_income_map <- tm_shape(philly_neighborhood_income) +\n  tm_polygons(\n    col = \"mean_income\",\n    style = \"quantile\",\n    n = 5,\n    palette = \"YlOrRd\",\n    title = \"Median Household Income\"\n  ) +\n  tm_layout(\n    main.title = \"Median Household Income by Neighborhood\",\n    main.title.position = \"center\",\n    outer.margins = c(0.10, 0.02, 0.02, 0.02),  # <-- more top padding\n    legend.outside = TRUE\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3->v4] `tm_polygons()`: instead of `style = \"quantile\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'n', 'palette' (rename to 'values') to\n  'tm_scale_intervals(<HERE>)'[v3->v4] `tm_polygons()`: migrate the argument(s) related to the legend of the\nvisual variable `fill` namely 'title' to 'fill.legend = tm_legend(<HERE>)'[v3->v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`\n```\n\n\n:::\n\n```{.r .cell-code}\nneighborhood_income_map\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"YlOrRd\" is named\n\"brewer.yl_or_rd\"\nMultiple palettes called \"yl_or_rd\" found: \"brewer.yl_or_rd\", \"matplotlib.yl_or_rd\". The first one, \"brewer.yl_or_rd\", is returned.\n\n[plot mode] fit legend/component: Some legend items or map compoments do not\nfit well, and are therefore rescaled.\nℹ Set the tmap option `component.autoscale = FALSE` to disable rescaling.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:**\n\nIn this visualization depicting median incomes of residents by neighborhoods, we observe continued spatial clustering of wealth indicators in areas like Center City, Northwest Philadelphia, and South Philadlephia. This is consistent with the basic aggregation of home sale prices on census tracts. The presence of high income in tandem with high housing cost serves as an indication of their relationship and justifies the use of economic predictors in our model. With this spatial auto-correlation, it is important that the model absorbs spatial variation by utilizing additional spatial features.   \n\n### Price vs. structural features\n\n#### 1. Number of Bathrooms\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(phl_sales_clean, aes(x = factor(number_of_bathrooms), y = sale_price)) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.color = \"firebrick\", outlier.alpha = 0.2) +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices by Number of Bathrooms\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Bathrooms\", \n       y = \"Sale Price\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:** Since number of bathrooms is a discrete variable, a scatter plot is not suitable to visualize this predictor's relationship with the target variable of sale price; therefore, we opted to use box plots instead. In this first plot, we see a distinct positive relationship between number of bathrooms and home sale price. Intuitively, this makes sense since homes with more bathrooms should on average sell at higher prices. Another trend is that there are more outliers in homes with less bathrooms (between 1 and 3). These outliers are likely due to external spatial factors such as neighborhoods. Housing prices tend to surge in highly desirable neighborhoods such as Rittenhouse Square, which explains the presence of many outliers plotted above the upper bound of these boxplots. Another trend is that variance of sale prices begins to significantly widen for homes with more than 3 bedrooms. This suggests that larger homes with more bathrooms experience more price dispersion relative to those with less bathrooms. Lastly, it is worth noting that there are very few observations of homes with 8 or 12 bathrooms, indicating that it would be beneficial to remove them from our dataset to better capture the true relationship between price and number of bathrooms.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(phl_sales_clean, aes(x = factor(number_of_bathrooms), y = log(sale_price))) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.color = \"firebrick\", outlier.alpha = 0.2) +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(title = \"Distribution of Log(Home Sale Prices) by Number of Bathrooms\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Bathrooms\", \n       y = \"Log(Sale Price)\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:** In addition, we also plotted with the y-axis transformed to the log of sales price. We notice that there is still a positive relationship that appears more linear than the first plot. The log transformation helps reduce the effect of extreme outliers by compressing the distribution of house sale prices. This transformation also serves to center the distributions as noted by the presence of both positive and negative outliers. These benefits suggest that log-transforming our target variable for a linear regression is the best suitable method to yield an accurate model. \n\n#### 2. Number of Bedrooms\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(phl_sales_clean, aes(x = factor(number_of_bedrooms), y = sale_price)) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.color = \"firebrick\", outlier.alpha = 0.2) +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices by Number of Bedrooms\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Bedrooms\", \n       y = \"Sale Price\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:** The above plot to measure the relationship between home sale price and number of bedrooms is positive, indicating that homes with more bedrooms tend to sell at higher prices. However, this relationship looks significantly less strong than the relationship between sale price and number of bathrooms. We observe many outliers across homes with various bedroom sizes, most notably those with 2 - 5 bedrooms. The intuition is that these size households are more likely to be sold on the market with higher variability in sales prices, particularly in the upper tail, demonstrating right-skew. These high outliers represent luxury properties that sell for abnormally high sale prices due to other external variables like neighborhood, size etc. Again, we have a small number of very large homes with 10, 11, and 12 bedrooms that are candidates for removal before building our model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(phl_sales_clean, aes(x = factor(number_of_bedrooms), y = log(sale_price))) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.color = \"firebrick\", outlier.alpha = 0.2) +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(title = \"Distribution of Log(Home Sale Prices) by Number of Bedrooms\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Bedrooms\", \n       y = \"Log(Sale Price)\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:** As before, we can log-transform the target variable log(sale price) to better visualize the relationship with number of bedrooms. We still see a positive relationship that appears more linear than in our earlier plot. As before, the log-transformation stabilizes the variance to mitigate outliers and centers the data demonstrated by outliers at both the upper and lower tails. The strength of the relationship still appears to be not as obvious as with the number of bathrooms. In other words, number of bathrooms may be a more suitable predictor of sale price from these EDA observations. To avoid the risk of multicollinearity, we will keep this finding in mind when determining what structural features should be included in our final model.\n\n#### 3. Total Livable Area\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(phl_sales_clean, aes(x = total_livable_area, sale_price)) +\n  geom_point(alpha = 0.1, size = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, linetype = 5, color = \"firebrick\") +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices by Total Livable Area\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Total Livable Area\", \n       y = \"Sale Price\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:** The plot represents the relationship between the non-transformed target sale price and predictor total livable area. We can see that the relationship to be positive with evidence of heavy right-skew with the majority of data points clustered in the bottom-left with less than 3000 sq ft of area and \\$500,000 price. Also, we notice that although the relationship is positive, it does not appear to be linear, a violation of a crucial assumption in linear regression. As before, there is the presence of luxury homes as large outliers that can pull the regression line upward, which would create biased estimates on model coefficients.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(phl_sales_clean, aes(x = log(total_livable_area), log(sale_price))) +\n  geom_point(alpha = 0.075, size = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, linetype = 5, color = \"firebrick\") +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Log(Home Sale Prices) by Total Livable Area\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Log(Total Livable Area)\", \n       y = \"Log(Sale Price)\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:** By log-transforming both sale price and total livable area, we visualize a relationship that appears much more linear. As we saw before, there seem to be more variability in homes with smaller areas that are more common in this dataset. The transformation has more of a uniform, symmetric spread of points above and below the regression line. We can interpret this relationship as increasing the percentage of total livable area will lead to some constant increase in the percentage of sale price with this transformation. We should keep at mind that the non-constant variance is alarming for potential heteroskedasticity in our model. Again, through the log-transformation of our target variable, we observe a more linear relationship, strengthening the notion for the need for this transformation in our modeling phase.\n\n#### 4. Age (Sale Date - Year Built)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(phl_sales_clean, aes(x = age, y = sale_price)) +\n  geom_point(alpha = 0.076, size = 1) +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices by Age\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Age\", \n       y = \"Sale Price\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:** In the above plot, it does not reveal any significant relationship between sale price and home age. The main issue is that most of the data is clustered at the bottom of the figure at low sale prices regardless of age. There are some noticeable outliers along with increased variability for middle-aged homes around 75 to 125 years old. In general, it seems that there newer homes (lower age) demonstrate somewhat higher price levels on average. However, from this plot alone, it is difficult to verify.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(phl_sales_clean, aes(x = age, log(sale_price))) +\n  geom_point(alpha = 0.075, size = 1) +\n  geom_smooth(method = \"loess\", span = 0.75, se = FALSE, color = \"firebrick\") +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Log(Home Sale Prices) by Age\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"Age\", \n       y = \"Log(Sale Price)\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:** After doing the trick to log-transform sale price, we see an interesting shape that somewhat resembles a crucial theory we learned in lecture. This theory outlines that Age has a U-shaped effect on price. Newer homes are sought after due to recent construction with more modern amenities, whereas very old homes are considered to have historic value or charm. The middle-aged homes are therefore the least desirable homes that likely are not modernized with significant wear and tear without the allure of a historic home. While this theory makes sense, it somewhat breaks down for these middle aged homes as their sale prices experience much more variability, which would make our model more at risk of heteroskedasticity. This is likely due to a majority of samples in our dataset within this range whose sale price cannot be explained by age alone. Therefore, it is wise to proceed with caution with using the age variable in building our predictive model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_age_groups <- phl_sales_clean |>\n  mutate(\n    age_group = case_when(\n      age < 20 ~ \"New (<20 years)\",\n      age < 80 ~ \"Middle (20–80 years)\",\n      age >= 80 ~ \"Historic (>80 years)\"\n    ),\n    age_group = factor(age_group, levels = c(\"New (<20 years)\", \"Middle (20–80 years)\", \"Historic (>80 years)\"))\n  )\n\nggplot(df_age_groups, aes(age_group, log(sale_price))) +\n  geom_boxplot(fill = \"lightcyan2\", outlier.colour = \"firebrick\", outlier.alpha = 0.2) +\n  labs(\n    title = \"Distribution of Log(Sale Price) by Age Group\",\n    subtitle = \"Philadelphia Residential Sales in 2023–2024\",\n    x = \"Age Group\", y = \"log(Sale Price)\",\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:** When we engineer a new age group feature, the U-shaped distribution does not appear to be valid in the case of our dataset. Using the age segmentations defined in class, it now appears as there is an inverse (negative) relationship between log(sale price) and age group, not a U-shape distribution. One hypothesis is that very old buildings in Philadelphia are too worn down or don't hold enough historic value to counteract its age. Whatever the reason may be, it seems that engineering a feature for age group is preferred over using age directly and to expect increasing age to a home to depreciate its value over time.\n\n### Price vs. spatial features\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(phl_sales_clean_sf_final, aes(x = EconKDE$lyr.1, y=sale_price)) +\n  geom_point(alpha = 0.1, size = 1) +\n  geom_smooth(method = \"lm\", se = FALSE, linetype = 5, color = \"firebrick\") +\n  scale_y_continuous(labels = label_dollar()) +\n  labs(title = \"Distribution of Home Sale Prices by Economic KDE Value\", \n       subtitle = \"For Philadelphia Residential Properties in 2023-2024\",\n       x = \"KDE\", \n       y = \"Sale Price\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(face = \"bold\")\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 13 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 13 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:**\nThe plot represents the relationship between the non-transformed target sale price and predictor KDE for economic activities. We can see that the relationship to be positive with evidence of heavy right-skew with the majority of data points clustered in the bottom-left with less than a KDE value of 0.000075 and \\$500,000 price. Also, we notice that although the relationship is positive, it does not appear to be linear, a violation of a crucial assumption in linear regression. It seems that the trend increases first till about 0.00008 and then decreases. As before, there is the presence of some homes as large outliers that can pull the regression line upward, which would create biased estimates on model coefficients.\n\n### One creative visualization: Sale Price Distribution Across City\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#join sales data with neighborhood data\nphilly_sales_neigh <- st_join(philly_neighborhoods, phl_sales_clean_sf_final, join = st_contains)\n\n# Summarize count of sales per neighborhood\nphilly_sales_count <- philly_sales_neigh %>%\n  group_by(NAME) %>%\n  summarize(\n    sales_count = n(),\n    .groups = \"drop\"\n  )\n\n# Plot\nggplot(philly_sales_count) +\n  geom_sf(aes(fill = sales_count), color = \"white\", size = 0.3) +\n  scale_fill_viridis_c(\n    option = \"inferno\",\n    direction = -1,\n    name = \"Number of Sales\",\n    trans = \"sqrt\"  \n  ) +\n  labs(\n    title = \"Number of Sales by Neighborhood (2023–2024)\",\n    subtitle = \"Philadelphia County\"\n  ) +\n  theme_void(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5),\n    legend.position = \"right\",\n    legend.key.height = unit(1.2, \"cm\")\n  )\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n**Interpretation:**\nBased on the map the number of sales is not evenly distributed across neighborhoods in Philadelphia County. Some of the neighborhoods in the east/northeast have a significant large number of home sales while the number of that in the south is lower. Moreover, the Center City area seems to also have a smaller number of sales compared to others, highly due to fewer number of housing units.\n\n\n# PHASE 3: FEATURE ENGINEERING\n\n### Final Data Cleaning from Structural EDA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 99th percentile of sales prices to remove\nprice_99_perc <- quantile(phl_sales_clean$sale_price, 0.99, na.rm = TRUE)\n\n# Relevant columns to keep for modeling\nrel_columns <- c(\n    # Location / Shape\n    \"census_tract\", \"shape\", \"location\", \"zip_code\",\n    # Target\n    \"sale_price\", \"log_price\",\n    # Regressors (and potential ones)\n    \"total_livable_area\", \"log_total_livable_area\",\n    \"number_of_bedrooms\", \"number_of_bathrooms\",\n    \"year_built\", \"age\", \"age_group\",\n    \"interior_condition\", \"quality_grade\" \n  )\n\nphl_sales_final <- phl_sales_clean |>\n  filter(\n    # Remove top 1% of sale price (extreme outliers)\n    # This creates an upper bound of around $2 million rather than $6 million to further reduce outlier effects in modeling\n    sale_price < price_99_perc,\n    # Remove bathrooms > 7\n    number_of_bathrooms < 8,\n    # Remove bedrooms > 9\n    number_of_bedrooms < 10\n  )|>\n  mutate(\n    # Log of sale price\n    log_price = log(sale_price),\n    # Log of total livable area\n    log_total_livable_area = log(total_livable_area),\n    # Age group buckets (new, middle_age, historic)\n    age_group = case_when(\n      age < 20 ~ \"New (<20)\",\n      age <= 80 ~ \"Middle (20–80)\",\n      age > 80 ~ \"Historic (>80)\"\n    ),\n    # For modeling as dummy variables\n    age_group = factor(age_group, levels = c(\"New (<20)\", \"Middle (20–80)\", \"Historic (>80)\"))\n  ) |>\n  # Select relevant columns\n  select(any_of(rel_columns))\n\n\n#convert housing prices data into point data\nphl_sales_final_sf = phl_sales_final%>%\n  mutate(geometry = st_as_sfc(shape)) %>%   # parse WKT into geometry\n  st_as_sf(crs = 2272)  \n#convert and match the crs\nphilly_schools_sf_final=philly_schools_sf_clean%>%\n  st_transform(2272)\nphilly_neighborhoods=philly_neighborhoods%>%\n  st_transform(2272)\nphilly_tract_map=philly_tract_map%>%\n  st_transform(2272)\n#merge them together\nphl_sales_final_sf_final=phl_sales_final_sf%>%\n  st_join(philly_tract_map,join=st_within)%>%\n  st_join(philly_neighborhoods,join = st_within)\nphl_sales_final_sf_final <- st_transform(phl_sales_final_sf_final, crs = st_crs(r_trees))\nphl_sales_final_sf_final$EconKDE <- raster::extract(r_Economic,phl_sales_final_sf_final)\nphl_sales_final_sf_final$TreeKDE <- raster::extract(r_trees, phl_sales_final_sf_final)  \nphl_sales_final_sf_final=phl_sales_final_sf_final%>%\n  st_transform(2272)\n```\n:::\n\n\n\n### Classifying Neighborhood\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#convert census tract into points\ncensus_points=st_centroid(philly_tract_map)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: st_centroid assumes attributes are constant over geometries\n```\n\n\n:::\n\n```{.r .cell-code}\npoints_joined <- st_join(census_points, philly_neighborhoods)\n\n# Calculate mean MHI for each polygon\nmean_mhi_by_poly <- points_joined %>%\n  st_drop_geometry() %>%             \n  group_by(MAPNAME) %>%            \n  summarise(meanMHI = mean(median_income, na.rm = TRUE))\n\n# Join the result back to the polygon layer\nphl_sales_final_sf_final <- phl_sales_final_sf_final %>%\n  left_join(mean_mhi_by_poly, by = \"MAPNAME\")%>%\n  st_as_sf() \n# reclassify the neighborhood data based on quantile (25%)\nphl_sales_final_sf_final$MHI_quantile <- cut(\n  phl_sales_final_sf_final$meanMHI,\n  breaks = quantile(\n    phl_sales_final_sf_final$meanMHI,\n    probs = seq(0, 1, 0.25),   \n    na.rm = TRUE\n  ),\n  include.lowest = TRUE,\n  labels = c(\"Q1 (lowest)\", \"Q2\", \"Q3\", \"Q4 (highest)\")\n)\n```\n:::\n\n\n### Calculating distance to schools using K-nearest method\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute distance matrix\ndist_matrix <- st_distance(phl_sales_final_sf_final, philly_schools_sf_final)\n\n# Extract the 3 smallest distances for each point\nnearest_3 <- apply(dist_matrix, 1, function(x) sort(x)[1:3])\n\n# Get the average or total distance if needed\nmean_nearest3 <- apply(dist_matrix, 1, function(x) mean(sort(x)[1:3]))\n\nphl_sales_final_sf_final$mean_3nn_dist <- mean_nearest3\n```\n:::\n\n\n\n### Summary table\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#reformat raster data into a \"readable\" format by stargazer\nphl_sales_final_sf_final <- phl_sales_final_sf_final %>%\n  mutate(EconKDE = EconKDE$lyr.1,\n         TreeKDE = TreeKDE$lyr.1) \n\n#exclude the unnecessary data\nsummary_data <- phl_sales_final_sf_final %>%\n  st_drop_geometry() %>%\n  select(-c(\n    census_tract, shape, NAME.x, NAME.y, MAPNAME,\n    Shape_Area, Shape_Leng, location, zip_code, GEOID, \n    variabl, age_group, quality_grade, LISTNAME, MHI_quantile,\n    estimat,moe,pct_bch,pct_vcn,pct_wht,mdn_ncm,fmly_hh,totl_hh\n  ))\n\n# Keep only numeric columns\nsummary_numeric <- summary_data %>%\n  select(where(is.numeric))\nsummary_numeric_df <- as.data.frame(summary_numeric)\n\n# Print as txt in R\nstargazer(summary_numeric_df,\n          type = \"text\",\n          title = \"Summary Statistics\",\n          digits = 2,\n          summary.stat = c(\"n\", \"mean\", \"sd\", \"min\", \"median\", \"max\"),\n          covariate.labels = c(\"Sale Price\", \"Log Price\", \"Total Livable Area\", \n                            \"Log Total Livable Area\", \"Bedrooms\", \"Bathrooms\", \n                            \"Year Built\", \"Age\", \"Interior Condition\", \n                            \"Median Income\",\"Family HH\", \n                            \"Total HH\", \"% Bachelors\", \"% Vacant\", \"% White\",\n                            \"Econ KDE\", \"Tree KDE\", \"Mean MHI\", \n                            \"Mean 3 closest School Dist\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSummary Statistics\n======================================================================================\nStatistic                    N       Mean     St. Dev.     Min     Median      Max    \n--------------------------------------------------------------------------------------\nSale Price                 21,807 289,078.80 245,777.60  10,000    235,000  2,285,000 \nLog Price                  21,807   12.28       0.81      9.21      12.37     14.64   \nTotal Livable Area         21,807  1,363.18    534.22      420      1,216     9,038   \nLog Total Livable Area     21,807    7.16       0.31      6.04      7.10       9.11   \nBedrooms                   21,807    3.07       0.71        0         3         9     \nBathrooms                  21,807    1.43       0.67        1         1         7     \nYear Built                 21,807  1,937.29    29.78      1,750     1,925     2,025   \nAge                        21,807   86.21      29.78       -2        98        274    \nInterior Condition         21,806    3.40       0.93        1         4         7     \nMedian Income              21,546 66,489.29  30,604.07   13,721    60,957    192,727  \nFamily HH                  21,805  1,095.76    434.94       0       1,054     2,484   \nTotal HH                   21,805  1,945.64    602.97       0       1,911     3,713   \n% Bachelors                21,802   32.42      22.73      1.50      26.33     94.84   \n% Vacant                   21,800    9.33       5.93      0.00      8.23      32.88   \n% White                    21,802   38.14      29.94      0.00      35.22     95.51   \nEcon KDE                   21,794   0.0000     0.0000    0.0000    0.0000     0.0002  \nTree KDE                   21,794   0.001      0.0002    0.0001    0.0005     0.001   \nMean MHI                   21,459 66,651.63  27,950.13  18,646.00 59,779.14 168,021.00\nMean 3 closest School Dist 21,805  2,598.76   1,190.85   336.99   2,363.89  11,109.39 \n--------------------------------------------------------------------------------------\n```\n\n\n:::\n:::\n\n### Final Cleaning Before Building the Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor_model_building <- phl_sales_final_sf_final %>%\n  st_drop_geometry() %>%\n  select(-c(\n    census_tract, shape, NAME.x, NAME.y,\n    Shape_Area, Shape_Leng, location, zip_code, GEOID, \n    variabl, LISTNAME, \n    estimat,moe,pct_bch,pct_vcn,pct_wht,mdn_ncm,fmly_hh,totl_hh\n  ))\n```\n:::\n\n\n\n\n### Justification of feature engineered variables\nWe have used a number of methods to create spatial features in both Phase 1 and 3. First, in Phase 1, since commercial and office POI and trees are point data, and the more they cluster the higher the housing price will be. As a result, we use Kernel Density method to estimate the density of them. Value of the cell was assign to the point (housing prices), if the point falls within it. \n\nSecond, as census tracts and neighborhood are polygon data, a st_within spatial join was used to join them with housing data. Values from polygon data will assign to the points when points fall within it. \n\nThird, as there are too many neighborhoods, it is hard to interpret the coefficient of them as it is a categorical variable. We reclassify it with four different categories based on quantile of MHI(25%). To calculate the MHI each neighborhood, we first take the centroid of each census tract and summarize them within each neighborhood. Then we take the mean of MHI of the tracts that fall within the neighborhood.  \n\nLastly, different from poi and trees, a high cluster of schools may not reflect a high housing price. As a result, instead of using density estimation, we use 3-nearest distance and take the mean to capture some of the closest schools.\n\n\n# PHASE 4: Model Building\n\n### create train/test data first (make workflow smoother)\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nn <- nrow(for_model_building)\n\n# 70% training, 30% testing\ntrain_indices <- sample(1:n, size = 0.7 * n)\ntrain_data <- for_model_building[train_indices, ]\ntest_data <- for_model_building[-train_indices, ]\n```\n:::\n\n\n### Building the model progressively\n#### Model 1: Individual characteristic only\n\n::: {.cell}\n\n```{.r .cell-code}\n#run regression based on houses own characteristic\noptions(scipen = 999)\n\nmodel1=lm(log_price~log_total_livable_area+number_of_bedrooms+number_of_bathrooms+age\n          +interior_condition+quality_grade,data=for_model_building)\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log_price ~ log_total_livable_area + number_of_bedrooms + \n    number_of_bathrooms + age + interior_condition + quality_grade, \n    data = for_model_building)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.9177 -0.3081  0.0803  0.3908  3.4233 \n\nCoefficients:\n                         Estimate Std. Error t value             Pr(>|t|)    \n(Intercept)             6.2999874  0.2126295  29.629 < 0.0000000000000002 ***\nlog_total_livable_area  0.9805519  0.0228959  42.826 < 0.0000000000000002 ***\nnumber_of_bedrooms     -0.1538913  0.0081175 -18.958 < 0.0000000000000002 ***\nnumber_of_bathrooms     0.2655967  0.0088561  29.990 < 0.0000000000000002 ***\nage                    -0.0020033  0.0001711 -11.709 < 0.0000000000000002 ***\ninterior_condition     -0.1940613  0.0054605 -35.539 < 0.0000000000000002 ***\nquality_grade5         -0.7390910  0.4705778  -1.571              0.11629    \nquality_gradeA          0.0251645  0.1751658   0.144              0.88577    \nquality_gradeA-         0.0295263  0.1814730   0.163              0.87075    \nquality_gradeA+         0.0611624  0.2121474   0.288              0.77312    \nquality_gradeB          0.0320486  0.1524305   0.210              0.83347    \nquality_gradeB-         0.1265652  0.1516088   0.835              0.40383    \nquality_gradeB+        -0.0474156  0.1571845  -0.302              0.76292    \nquality_gradeC         -0.1452483  0.1498012  -0.970              0.33225    \nquality_gradeC-        -0.1027752  0.1517525  -0.677              0.49825    \nquality_gradeC+        -0.0267014  0.1500292  -0.178              0.85874    \nquality_gradeD          0.1473498  0.1572472   0.937              0.34874    \nquality_gradeD-        -0.2209235  0.3197212  -0.691              0.48958    \nquality_gradeD+         0.2265099  0.1814849   1.248              0.21201    \nquality_gradeE         -0.4206165  0.2143947  -1.962              0.04979 *  \nquality_gradeE-        -0.6936639  0.2495913  -2.779              0.00545 ** \nquality_gradeE+        -0.3686049  0.2496201  -1.477              0.13978    \nquality_gradeS          0.0710844  0.4709353   0.151              0.88002    \nquality_gradeX-         0.3722878  0.4722638   0.788              0.43053    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6313 on 21245 degrees of freedom\n  (因为不存在，538个观察量被删除了)\nMultiple R-squared:  0.3771,\tAdjusted R-squared:  0.3764 \nF-statistic: 559.2 on 23 and 21245 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n\n```{.r .cell-code}\n#check colinearity\nvif(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                           GVIF Df GVIF^(1/(2*Df))\nlog_total_livable_area 2.559182  1        1.599744\nnumber_of_bedrooms     1.754091  1        1.324421\nnumber_of_bathrooms    1.745491  1        1.321170\nage                    1.137622  1        1.066594\ninterior_condition     1.196302  1        1.093756\nquality_grade          1.631892 18        1.013697\n```\n\n\n:::\n\n```{.r .cell-code}\n#vif looks fine, check heteroskedasticity\n\nbptest(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tstudentized Breusch-Pagan test\n\ndata:  model1\nBP = 881.72, df = 23, p-value < 0.00000000000000022\n```\n\n\n:::\n\n```{.r .cell-code}\n#p-value is way too small, implying more variables may be needed (make sense)\n\n#calculate the RMSE\nmodel_train_1 <- lm(log_price~log_total_livable_area+number_of_bedrooms+number_of_bathrooms+age+interior_condition+quality_grade,data = train_data)\ntest_predictions_1 <- predict(model_train_1, newdata = test_data)\nrmse_test_1 <- sqrt(mean((test_data$log_price - test_predictions_1)^2,na.rm = TRUE))\nrmse_train_1 <- summary(model_train_1)$sigma\n\n\nplot(model1)\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-41-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-41-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-41-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-41-4.png){width=672}\n:::\n:::\n\nIn residual plot, more observations are clustered when fitted value is lower, indicating bad distribution of residuals and nonlinearity. \n\nSame issue is reflected in Q-Q plot as well, the unlinearity revels the distribution of residual is not normal.\n\nThere is also heteroskedasticity, as the scale location shows, the line is not linear at all. \n\nThe outliers seems to have small influence on the leverage,as the line is almost linear shown in the last graph\n\n\n\n#### Model 2: add census variables into regression\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(scipen = 999)\n\nmodel2=lm(log_price~log_total_livable_area+number_of_bedrooms+number_of_bathrooms+age\n          +interior_condition+median_income+I(family_hh/total_hh)\n          +pct_bachelors+pct_vacant+pct_white+quality_grade ,data=for_model_building)\n\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log_price ~ log_total_livable_area + number_of_bedrooms + \n    number_of_bathrooms + age + interior_condition + median_income + \n    I(family_hh/total_hh) + pct_bachelors + pct_vacant + pct_white + \n    quality_grade, data = for_model_building)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0624 -0.1965  0.0620  0.2672  3.4712 \n\nCoefficients:\n                            Estimate    Std. Error t value             Pr(>|t|)\n(Intercept)             8.1058037963  0.1728369352  46.899 < 0.0000000000000002\nlog_total_livable_area  0.5538846916  0.0187767976  29.498 < 0.0000000000000002\nnumber_of_bedrooms      0.0023439696  0.0066684851   0.351              0.72522\nnumber_of_bathrooms     0.1663096478  0.0071583003  23.233 < 0.0000000000000002\nage                    -0.0015366030  0.0001464531 -10.492 < 0.0000000000000002\ninterior_condition     -0.1714564249  0.0044711059 -38.348 < 0.0000000000000002\nmedian_income           0.0000006343  0.0000002553   2.484              0.01299\nI(family_hh/total_hh)   0.1443236566  0.0352559283   4.094            0.0000426\npct_bachelors           0.0098889478  0.0003722161  26.568 < 0.0000000000000002\npct_vacant             -0.0166358372  0.0006790400 -24.499 < 0.0000000000000002\npct_white               0.0060401571  0.0001902132  31.755 < 0.0000000000000002\nquality_grade5         -0.4344933604  0.3739074939  -1.162              0.24523\nquality_gradeA          0.1107178862  0.1393149268   0.795              0.42678\nquality_gradeA-         0.0700769181  0.1443339817   0.486              0.62731\nquality_gradeA+         0.1136545224  0.1687270806   0.674              0.50057\nquality_gradeB          0.0975160749  0.1212863598   0.804              0.42140\nquality_gradeB-         0.1799630519  0.1206855192   1.491              0.13593\nquality_gradeB+         0.0245424614  0.1250391566   0.196              0.84439\nquality_gradeC          0.1650394170  0.1193943723   1.382              0.16689\nquality_gradeC-         0.1301253997  0.1209034284   1.076              0.28182\nquality_gradeC+         0.1870692517  0.1195349845   1.565              0.11760\nquality_gradeD          0.1868565185  0.1253851839   1.490              0.13617\nquality_gradeD-        -0.0812834412  0.2541690364  -0.320              0.74912\nquality_gradeD+         0.3987094613  0.1444507895   2.760              0.00578\nquality_gradeE         -0.0531677446  0.1704506786  -0.312              0.75510\nquality_gradeE-         0.1439129539  0.2137544484   0.673              0.50079\nquality_gradeE+        -0.0010031690  0.1985273954  -0.005              0.99597\nquality_gradeS          0.3750806992  0.3742472792   1.002              0.31625\nquality_gradeX-         0.0436059017  0.3755434914   0.116              0.90756\n                          \n(Intercept)            ***\nlog_total_livable_area ***\nnumber_of_bedrooms        \nnumber_of_bathrooms    ***\nage                    ***\ninterior_condition     ***\nmedian_income          *  \nI(family_hh/total_hh)  ***\npct_bachelors          ***\npct_vacant             ***\npct_white              ***\nquality_grade5            \nquality_gradeA            \nquality_gradeA-           \nquality_gradeA+           \nquality_gradeB            \nquality_gradeB-           \nquality_gradeB+           \nquality_gradeC            \nquality_gradeC-           \nquality_gradeC+           \nquality_gradeD            \nquality_gradeD-           \nquality_gradeD+        ** \nquality_gradeE            \nquality_gradeE-           \nquality_gradeE+           \nquality_gradeS            \nquality_gradeX-           \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5016 on 20981 degrees of freedom\n  (因为不存在，797个观察量被删除了)\nMultiple R-squared:  0.604,\tAdjusted R-squared:  0.6035 \nF-statistic:  1143 on 28 and 20981 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n\n```{.r .cell-code}\n#number of bedroom becomes statistical insignificant after controling census variable\n\n#check colinearity\nvif(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                           GVIF Df GVIF^(1/(2*Df))\nlog_total_livable_area 2.698470  1        1.642702\nnumber_of_bedrooms     1.852123  1        1.360927\nnumber_of_bathrooms    1.789763  1        1.337820\nage                    1.315849  1        1.147105\ninterior_condition     1.251877  1        1.118873\nmedian_income          5.077347  1        2.253297\nI(family_hh/total_hh)  1.903464  1        1.379661\npct_bachelors          5.954738  1        2.440233\npct_vacant             1.356028  1        1.164486\npct_white              2.696400  1        1.642072\nquality_grade          1.776112 18        1.016084\n```\n\n\n:::\n\n```{.r .cell-code}\n#edu_attainment and mhi may have muticolinearity\n\nbptest(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tstudentized Breusch-Pagan test\n\ndata:  model2\nBP = 1068.9, df = 28, p-value < 0.00000000000000022\n```\n\n\n:::\n\n```{.r .cell-code}\n#p-value is way too small, implying more variables may be needed (make sense)\n\n#calculate the RMSE\nmodel_train_2 <- lm(log_price~log_total_livable_area+number_of_bedrooms\n                    +number_of_bathrooms+age+interior_condition+median_income\n                    +I(family_hh/total_hh)\n                    +pct_bachelors+pct_vacant+pct_white\n                    +quality_grade,data = train_data)\ntest_predictions_2 <- predict(model_train_2, newdata = test_data)\nrmse_test_2 <- sqrt(mean((test_data$log_price - test_predictions_2)^2,na.rm = TRUE))\nrmse_train_2 <- summary(model_train_2)$sigma\n\n\n\nplot(model2)\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-42-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-42-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-42-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-42-4.png){width=672}\n:::\n:::\n\nThe residual plot for model 2 looks much better than that in model 1. The number of observations are clustered when fitted value is lower decreases, indicating better distribution of residuals. The non-linearity issue also gets better\n\nQ-Q plot still does not look good, especially for the outliers. It seems that outliers is influencing the normality of residuals\n\nThere is also heteroskedasticity, as the scale location shows, the line is not linear at all. \n\nThe outlier seems to have small influence on the leverage,as the line is almost linear shown in the last graph\n\n#### Model 3: add spatial variables into regression\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(scipen = 999)\n\nmodel3=lm(log_price~log_total_livable_area+number_of_bedrooms+number_of_bathrooms+age\n          +interior_condition+median_income+I(family_hh/total_hh)\n          +pct_bachelors+pct_vacant+pct_white+EconKDE+I(EconKDE^2)+TreeKDE\n          +mean_3nn_dist+quality_grade,data=for_model_building)\n\nsummary(model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log_price ~ log_total_livable_area + number_of_bedrooms + \n    number_of_bathrooms + age + interior_condition + median_income + \n    I(family_hh/total_hh) + pct_bachelors + pct_vacant + pct_white + \n    EconKDE + I(EconKDE^2) + TreeKDE + mean_3nn_dist + quality_grade, \n    data = for_model_building)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.1314 -0.1880  0.0606  0.2601  3.5035 \n\nCoefficients:\n                                  Estimate          Std. Error t value\n(Intercept)                   8.4825695004        0.1727822499  49.094\nlog_total_livable_area        0.5200971790        0.0186445116  27.895\nnumber_of_bedrooms            0.0151181173        0.0066533469   2.272\nnumber_of_bathrooms           0.1496901250        0.0071252064  21.009\nage                          -0.0016769416        0.0001509123 -11.112\ninterior_condition           -0.1845077281        0.0044744419 -41.236\nmedian_income                 0.0000015682        0.0000002562   6.121\nI(family_hh/total_hh)        -0.0137941162        0.0373096992  -0.370\npct_bachelors                 0.0111678353        0.0004338910  25.739\npct_vacant                   -0.0128219856        0.0007592577 -16.888\npct_white                     0.0044734242        0.0002090116  21.403\nEconKDE                   -5950.7059824794      394.3683600993 -15.089\nI(EconKDE^2)           35299866.1829479113  1854560.8472317727  19.034\nTreeKDE                     -71.7979060016       37.9804998669  -1.890\nmean_3nn_dist                 0.0000043985        0.0000037194   1.183\nquality_grade5               -0.3950544450        0.3695503925  -1.069\nquality_gradeA                0.1356751990        0.1376524779   0.986\nquality_gradeA-               0.1443683605        0.1426471818   1.012\nquality_gradeA+               0.1576314931        0.1667256811   0.945\nquality_gradeB                0.1627427910        0.1198662649   1.358\nquality_gradeB-               0.2286853144        0.1192576041   1.918\nquality_gradeB+               0.0990217756        0.1236050448   0.801\nquality_gradeC                0.2219126097        0.1179872232   1.881\nquality_gradeC-               0.1857588062        0.1194931791   1.555\nquality_gradeC+               0.2378951571        0.1181171045   2.014\nquality_gradeD                0.2702293545        0.1239775347   2.180\nquality_gradeD-              -0.0049626669        0.2511414610  -0.020\nquality_gradeD+               0.4364251755        0.1427211650   3.058\nquality_gradeE                0.0804800421        0.1685057337   0.478\nquality_gradeE-               0.2647980259        0.2112607536   1.253\nquality_gradeE+               0.1128301761        0.1961986400   0.575\nquality_gradeS                0.4843469009        0.3698006476   1.310\nquality_gradeX-               0.1420367199        0.3712200734   0.383\n                                   Pr(>|t|)    \n(Intercept)            < 0.0000000000000002 ***\nlog_total_livable_area < 0.0000000000000002 ***\nnumber_of_bedrooms                  0.02308 *  \nnumber_of_bathrooms    < 0.0000000000000002 ***\nage                    < 0.0000000000000002 ***\ninterior_condition     < 0.0000000000000002 ***\nmedian_income                0.000000000949 ***\nI(family_hh/total_hh)               0.71160    \npct_bachelors          < 0.0000000000000002 ***\npct_vacant             < 0.0000000000000002 ***\npct_white              < 0.0000000000000002 ***\nEconKDE                < 0.0000000000000002 ***\nI(EconKDE^2)           < 0.0000000000000002 ***\nTreeKDE                             0.05872 .  \nmean_3nn_dist                       0.23699    \nquality_grade5                      0.28508    \nquality_gradeA                      0.32432    \nquality_gradeA-                     0.31152    \nquality_gradeA+                     0.34444    \nquality_gradeB                      0.17457    \nquality_gradeB-                     0.05518 .  \nquality_gradeB+                     0.42307    \nquality_gradeC                      0.06001 .  \nquality_gradeC-                     0.12007    \nquality_gradeC+                     0.04402 *  \nquality_gradeD                      0.02929 *  \nquality_gradeD-                     0.98423    \nquality_gradeD+                     0.00223 ** \nquality_gradeE                      0.63293    \nquality_gradeE-                     0.21007    \nquality_gradeE+                     0.56524    \nquality_gradeS                      0.19029    \nquality_gradeX-                     0.70200    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4955 on 20966 degrees of freedom\n  (因为不存在，808个观察量被删除了)\nMultiple R-squared:  0.6137,\tAdjusted R-squared:  0.6131 \nF-statistic:  1041 on 32 and 20966 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n\n```{.r .cell-code}\n#percent of family hh become not significant, number of bedrooms become significant again\n\n\n#check colinearity\nvif(model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            GVIF Df GVIF^(1/(2*Df))\nlog_total_livable_area  2.724254  1        1.650532\nnumber_of_bedrooms      1.887567  1        1.373888\nnumber_of_bathrooms     1.815898  1        1.347552\nage                     1.431213  1        1.196333\ninterior_condition      1.284072  1        1.133169\nmedian_income           5.237298  1        2.288514\nI(family_hh/total_hh)   2.182899  1        1.477464\npct_bachelors           8.288260  1        2.878934\npct_vacant              1.736725  1        1.317849\npct_white               3.333800  1        1.825870\nEconKDE                22.223230  1        4.714152\nI(EconKDE^2)           13.997982  1        3.741388\nTreeKDE                 4.808879  1        2.192916\nmean_3nn_dist           1.668969  1        1.291886\nquality_grade           1.818447 18        1.016749\n```\n\n\n:::\n\n```{.r .cell-code}\n#very sure edu_attainment and mhi may have muticolinearity, make sense EconKDE and its squared term have high vif score as we are taking quadratic term\n\nbptest(model3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tstudentized Breusch-Pagan test\n\ndata:  model3\nBP = 1167.1, df = 32, p-value < 0.00000000000000022\n```\n\n\n:::\n\n```{.r .cell-code}\n#p-value is way too small, implying more variables may be needed \n\n#calculate the RMSE\nmodel_train_3 <- lm(log_price~log_total_livable_area+number_of_bedrooms+number_of_bathrooms+age\n          +interior_condition+median_income+I(family_hh/total_hh)\n          +pct_bachelors+pct_vacant+pct_white+EconKDE+I(EconKDE^2)+TreeKDE\n          +mean_3nn_dist+quality_grade,data = train_data)\ntest_predictions_3 <- predict(model_train_3, newdata = test_data)\nrmse_test_3 <- sqrt(mean((test_data$log_price - test_predictions_3)^2,na.rm = TRUE))\nrmse_train_3 <- summary(model_train_3)$sigma\n\n\n\n\nplot(model3)\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-43-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-43-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-43-4.png){width=672}\n:::\n:::\n\nThe residual plot for model 3 does not change that much compared to model 2. The majority of the issues remain the same\n\n#### Model 4: add fixed variable and interaction terms into regression\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(scipen = 999)\n\nmodel4=lm(log_price~log_total_livable_area+number_of_bedrooms+number_of_bathrooms+age\n          +interior_condition+median_income+I(family_hh/total_hh)\n          +pct_bachelors+pct_vacant+pct_white+EconKDE+I(EconKDE^2)+TreeKDE\n          +mean_3nn_dist+MHI_quantile*age,data=for_model_building)\n\nsummary(model4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = log_price ~ log_total_livable_area + number_of_bedrooms + \n    number_of_bathrooms + age + interior_condition + median_income + \n    I(family_hh/total_hh) + pct_bachelors + pct_vacant + pct_white + \n    EconKDE + I(EconKDE^2) + TreeKDE + mean_3nn_dist + MHI_quantile * \n    age, data = for_model_building)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0539 -0.1819  0.0537  0.2435  3.5634 \n\nCoefficients:\n                                        Estimate          Std. Error t value\n(Intercept)                         8.7570416602        0.1210319078  72.353\nlog_total_livable_area              0.5092460398        0.0168380119  30.244\nnumber_of_bedrooms                  0.0175194574        0.0064478965   2.717\nnumber_of_bathrooms                 0.1512138374        0.0067673389  22.345\nage                                -0.0042403747        0.0004234892 -10.013\ninterior_condition                 -0.1643092293        0.0042147921 -38.984\nmedian_income                       0.0000004415        0.0000002615   1.688\nI(family_hh/total_hh)               0.0427171820        0.0361347567   1.182\npct_bachelors                       0.0083645685        0.0004316972  19.376\npct_vacant                         -0.0109486916        0.0007418567 -14.758\npct_white                           0.0042606473        0.0002195901  19.403\nEconKDE                         -3726.6639491539      388.2838619342  -9.598\nI(EconKDE^2)                 26476925.8415185846  1802282.7960894341  14.691\nTreeKDE                           -31.9325074043       37.2000867459  -0.858\nmean_3nn_dist                       0.0000163143        0.0000036828   4.430\nMHI_quantileQ2                      0.1359917901        0.0510125426   2.666\nMHI_quantileQ3                     -0.0226401590        0.0468922002  -0.483\nMHI_quantileQ4 (highest)           -0.0735598569        0.0450879150  -1.631\nage:MHI_quantileQ2                  0.0013681771        0.0005425357   2.522\nage:MHI_quantileQ3                  0.0026871056        0.0004898476   5.486\nage:MHI_quantileQ4 (highest)        0.0041725660        0.0004487845   9.297\n                                         Pr(>|t|)    \n(Intercept)                  < 0.0000000000000002 ***\nlog_total_livable_area       < 0.0000000000000002 ***\nnumber_of_bedrooms                        0.00659 ** \nnumber_of_bathrooms          < 0.0000000000000002 ***\nage                          < 0.0000000000000002 ***\ninterior_condition           < 0.0000000000000002 ***\nmedian_income                             0.09139 .  \nI(family_hh/total_hh)                     0.23715    \npct_bachelors                < 0.0000000000000002 ***\npct_vacant                   < 0.0000000000000002 ***\npct_white                    < 0.0000000000000002 ***\nEconKDE                      < 0.0000000000000002 ***\nI(EconKDE^2)                 < 0.0000000000000002 ***\nTreeKDE                                   0.39068    \nmean_3nn_dist                        0.0000094787 ***\nMHI_quantileQ2                            0.00769 ** \nMHI_quantileQ3                            0.62923    \nMHI_quantileQ4 (highest)                  0.10280    \nage:MHI_quantileQ2                        0.01168 *  \nage:MHI_quantileQ3                   0.0000000417 ***\nage:MHI_quantileQ4 (highest) < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4831 on 21165 degrees of freedom\n  (因为不存在，621个观察量被删除了)\nMultiple R-squared:  0.6403,\tAdjusted R-squared:   0.64 \nF-statistic:  1884 on 20 and 21165 DF,  p-value: < 0.00000000000000022\n```\n\n\n:::\n\n```{.r .cell-code}\n#percent of family hh become not significant, number of bedrooms become significant again\n\n\n#check colinearity\nvif(model4)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nthere are higher-order terms (interactions) in this model\nconsider setting type = 'predictor'; see ?vif\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                              GVIF Df GVIF^(1/(2*Df))\nlog_total_livable_area    2.513009  1        1.585247\nnumber_of_bedrooms        1.887408  1        1.373830\nnumber_of_bathrooms       1.889034  1        1.374421\nage                      14.583408  1        3.818823\ninterior_condition        1.406526  1        1.185970\nmedian_income             5.855517  1        2.419817\nI(family_hh/total_hh)     2.185634  1        1.478389\npct_bachelors             8.813745  1        2.968795\npct_vacant                1.758337  1        1.326023\npct_white                 3.923157  1        1.980696\nEconKDE                  23.401381  1        4.837497\nI(EconKDE^2)             14.581832  1        3.818616\nTreeKDE                   4.944515  1        2.223626\nmean_3nn_dist             1.762006  1        1.327406\nMHI_quantile           4483.858830  3        4.060772\nage:MHI_quantile       4564.873265  3        4.072910\n```\n\n\n:::\n\n```{.r .cell-code}\n#very sure edu_attainment and mhi may have muticolinearity\n#tree seems to be correlated with neighborhood (make sense)\n#make sense EconKDE and its squared term have high vif score as we are taking quadratic term\n\nbptest(model4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tstudentized Breusch-Pagan test\n\ndata:  model4\nBP = 1221.2, df = 20, p-value < 0.00000000000000022\n```\n\n\n:::\n\n```{.r .cell-code}\n#p-value is way too small, implying more variables may be needed \n\n#calculate the RMSE\nmodel_train_4 <- lm(log_price~log_total_livable_area+number_of_bedrooms+number_of_bathrooms+age\n          +interior_condition+median_income+I(family_hh/total_hh)\n          +pct_bachelors+pct_vacant+pct_white+EconKDE+I(EconKDE^2)+TreeKDE\n          +mean_3nn_dist+MHI_quantile*age,data = train_data)\ntest_predictions_4 <- predict(model_train_4, newdata = test_data)\nrmse_test_4 <- sqrt(mean((test_data$log_price - test_predictions_4)^2,na.rm = TRUE))\nrmse_train_4 <- summary(model_train_4)$sigma\n\nplot(model4)\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-44-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-44-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-44-4.png){width=672}\n:::\n:::\n\n\n#### comparison table (RMSE, R² for 4 different models you constructed in your process)\n\n::: {.cell}\n\n```{.r .cell-code}\nrmse_values = c(rmse_test_1,rmse_test_2,rmse_test_3,rmse_test_4)\nadj_r2 = c(\n  summary(model1)$adj.r.squared,\n  summary(model2)$adj.r.squared,\n  summary(model3)$adj.r.squared,\n  summary(model4)$adj.r.squared\n)\nmodel_summary <- data.frame(\n  Model = c(\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\"),\n  RMSE = round(rmse_values, 3),\n  Adj_R2 = round(adj_r2, 3)\n)\n\n\n\nstargazer(model_summary,\n          type = \"text\",\n          title = \"Model Performance Summary\",\n          summary = FALSE,\n          rownames = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel Performance Summary\n====================\nModel   RMSE  Adj_R2\n--------------------\nModel 1 0.620 0.376 \nModel 2 0.491 0.604 \nModel 3 0.485 0.613 \nModel 4 0.475 0.640 \n--------------------\n```\n\n\n:::\n:::\n\n\n\n\n### stargazer regression results\n\n::: {.cell}\n\n```{.r .cell-code}\nstargazer(model1,model2,model3,model4,\n          type = \"text\", #could be changed to text if needed\n          title = \"Model Results\",\n          dep.var.labels = c(\"Log of Sale Price\"),\n          covariate.labels = c(\n            \"Log(Total Livable Area)\",\n            \"Number of Bedrooms\",\n            \"Number of Bathrooms\",\n            \"Building Age\",\n            \"Interior Condition\",\n            \"Median Household Income\",\n            \"Family Household Share (Family HH / Total HH)\",\n            \"% Bachelor's Degree Holders\",\n            \"% Vacant Housing Units\",\n            \"% White Population\",\n            \"Economic Density (EconKDE)\",\n            \"Economic Density² (EconKDE²)\",\n            \"Tree Density (TreeKDE)\",\n            \"Mean 3-Nearest Neighbor Distance\"\n          ),\n          omit.stat = c(\"f\", \"ser\"),\n          digits = 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel Results\n=====================================================================================================\n                                                                Dependent variable:                  \n                                              -------------------------------------------------------\n                                                                 Log of Sale Price                   \n                                                 (1)       (2)           (3)               (4)       \n-----------------------------------------------------------------------------------------------------\nLog(Total Livable Area)                       0.981***  0.554***      0.520***          0.509***     \n                                               (0.023)   (0.019)       (0.019)           (0.017)     \n                                                                                                     \nNumber of Bedrooms                            -0.154***   0.002        0.015**          0.018***     \n                                               (0.008)   (0.007)       (0.007)           (0.006)     \n                                                                                                     \nNumber of Bathrooms                           0.266***  0.166***      0.150***          0.151***     \n                                               (0.009)   (0.007)       (0.007)           (0.007)     \n                                                                                                     \nBuilding Age                                  -0.002*** -0.002***     -0.002***         -0.004***    \n                                              (0.0002)  (0.0001)      (0.0002)          (0.0004)     \n                                                                                                     \nInterior Condition                            -0.194*** -0.171***     -0.185***         -0.164***    \n                                               (0.005)   (0.004)       (0.004)           (0.004)     \n                                                                                                     \nMedian Household Income                                 0.00000**    0.00000***         0.00000*     \n                                                        (0.00000)     (0.00000)         (0.00000)    \n                                                                                                     \nFamily Household Share (Family HH / Total HH)           0.144***       -0.014             0.043      \n                                                         (0.035)       (0.037)           (0.036)     \n                                                                                                     \n% Bachelor's Degree Holders                             0.010***      0.011***          0.008***     \n                                                        (0.0004)      (0.0004)          (0.0004)     \n                                                                                                     \n% Vacant Housing Units                                  -0.017***     -0.013***         -0.011***    \n                                                         (0.001)       (0.001)           (0.001)     \n                                                                                                     \n% White Population                                      0.006***      0.004***          0.004***     \n                                                        (0.0002)      (0.0002)          (0.0002)     \n                                                                                                     \nEconomic Density (EconKDE)                                          -5,950.706***     -3,726.664***  \n                                                                      (394.368)         (388.284)    \n                                                                                                     \nEconomic Density² (EconKDE²)                                      35,299,866.000*** 26,476,926.000***\n                                                                   (1,854,561.000)   (1,802,283.000) \n                                                                                                     \nTree Density (TreeKDE)                                                -71.798*           -31.933     \n                                                                      (37.980)          (37.200)     \n                                                                                                     \nMean 3-Nearest Neighbor Distance                                       0.00000         0.00002***    \n                                                                      (0.00000)         (0.00000)    \n                                                                                                     \nquality_grade5                                 -0.739    -0.434        -0.395                        \n                                               (0.471)   (0.374)       (0.370)                       \n                                                                                                     \nquality_gradeA                                  0.025     0.111         0.136                        \n                                               (0.175)   (0.139)       (0.138)                       \n                                                                                                     \nquality_gradeA-                                 0.030     0.070         0.144                        \n                                               (0.181)   (0.144)       (0.143)                       \n                                                                                                     \nquality_gradeA+                                 0.061     0.114         0.158                        \n                                               (0.212)   (0.169)       (0.167)                       \n                                                                                                     \nquality_gradeB                                  0.032     0.098         0.163                        \n                                               (0.152)   (0.121)       (0.120)                       \n                                                                                                     \nquality_gradeB-                                 0.127     0.180        0.229*                        \n                                               (0.152)   (0.121)       (0.119)                       \n                                                                                                     \nquality_gradeB+                                -0.047     0.025         0.099                        \n                                               (0.157)   (0.125)       (0.124)                       \n                                                                                                     \nquality_gradeC                                 -0.145     0.165        0.222*                        \n                                               (0.150)   (0.119)       (0.118)                       \n                                                                                                     \nquality_gradeC-                                -0.103     0.130         0.186                        \n                                               (0.152)   (0.121)       (0.119)                       \n                                                                                                     \nquality_gradeC+                                -0.027     0.187        0.238**                       \n                                               (0.150)   (0.120)       (0.118)                       \n                                                                                                     \nquality_gradeD                                  0.147     0.187        0.270**                       \n                                               (0.157)   (0.125)       (0.124)                       \n                                                                                                     \nquality_gradeD-                                -0.221    -0.081        -0.005                        \n                                               (0.320)   (0.254)       (0.251)                       \n                                                                                                     \nquality_gradeD+                                 0.227   0.399***      0.436***                       \n                                               (0.181)   (0.144)       (0.143)                       \n                                                                                                     \nquality_gradeE                                -0.421**   -0.053         0.080                        \n                                               (0.214)   (0.170)       (0.169)                       \n                                                                                                     \nquality_gradeE-                               -0.694***   0.144         0.265                        \n                                               (0.250)   (0.214)       (0.211)                       \n                                                                                                     \nquality_gradeE+                                -0.369    -0.001         0.113                        \n                                               (0.250)   (0.199)       (0.196)                       \n                                                                                                     \nquality_gradeS                                  0.071     0.375         0.484                        \n                                               (0.471)   (0.374)       (0.370)                       \n                                                                                                     \nquality_gradeX-                                 0.372     0.044         0.142                        \n                                               (0.472)   (0.376)       (0.371)                       \n                                                                                                     \nMHI_quantileQ2                                                                          0.136***     \n                                                                                         (0.051)     \n                                                                                                     \nMHI_quantileQ3                                                                           -0.023      \n                                                                                         (0.047)     \n                                                                                                     \nMHI_quantileQ4 (highest)                                                                 -0.074      \n                                                                                         (0.045)     \n                                                                                                     \nage:MHI_quantileQ2                                                                       0.001**     \n                                                                                         (0.001)     \n                                                                                                     \nage:MHI_quantileQ3                                                                      0.003***     \n                                                                                        (0.0005)     \n                                                                                                     \nage:MHI_quantileQ4 (highest)                                                            0.004***     \n                                                                                        (0.0004)     \n                                                                                                     \nConstant                                      6.300***  8.106***      8.483***          8.757***     \n                                               (0.213)   (0.173)       (0.173)           (0.121)     \n                                                                                                     \n-----------------------------------------------------------------------------------------------------\nObservations                                   21,269    21,010        20,999            21,186      \nR2                                              0.377     0.604         0.614             0.640      \nAdjusted R2                                     0.376     0.604         0.613             0.640      \n=====================================================================================================\nNote:                                                                     *p<0.1; **p<0.05; ***p<0.01\n```\n\n\n:::\n:::\n\n### Coefficient Interpretations\n\n**Structural Features:**\n- **Log(Total Livable Area) (β = 0.509, p < 0.001)**: A 1% increase in total livable area is associated with a 0.509% increase in sale price, holding all other factors constant. This represents the strongest predictor in our model, indicating that size is the primary driver of housing value in Philadelphia.\n\n- **Number of Bedrooms (β = 0.018, p < 0.001)**: Each additional bedroom is associated with approximately a 1.8% increase in sale price. This positive coefficient suggests that bedrooms add value, though the effect is modest compared to other structural features.\n\n- **Number of Bathrooms (β = 0.151, p < 0.001)**: Each additional bathroom is associated with approximately a 16.3% increase in sale price. This substantial effect indicates that bathrooms are highly valued amenities in Philadelphia's housing market, likely reflecting both functional utility and luxury appeal.\n\n- **Building Age (β = -0.004, p < 0.001)**: Each additional year of building age is associated with approximately a 0.4% decrease in sale price. This suggests that newer homes command premium prices, reflecting depreciation over time and the value of modern amenities and construction standards.\n\n- **Interior Condition (β = -0.164, p < 0.001)**: Each unit increase in interior condition rating (where higher numbers indicate worse condition) is associated with approximately a 17.9% decrease in sale price. This substantial effect demonstrates the critical importance of property condition in determining market value.\n\n**Neighborhood Demographics:**\n- **Median Household Income (β = 0.00000, p < 0.1)**: While statistically significant, the coefficient is extremely small, suggesting that tract-level median income has a minimal direct effect on individual property prices when controlling for other factors.\n\n- **% Bachelor's Degree Holders (β = 0.008, p < 0.001)**: A 1 percentage point increase in the proportion of residents with bachelor's degrees is associated with approximately a 0.8% increase in sale price. This reflects the premium associated with highly educated neighborhoods or higher ability to pay for degree-holding buyers.\n\n- **% Vacant Housing Units (β = -0.011, p < 0.001)**: A 1 percentage point increase in vacancy rate is associated with approximately a 1.1% decrease in sale price. This negative relationship reflects the detrimental effects of neighborhood blight and disinvestment on property values.\n\n- **% White Population (β = 0.004, p < 0.001)**: A 1 percentage point increase in the white population share is associated with approximately a 0.4% increase in sale price. This coefficient likely captures both historical patterns of neighborhood investment and ongoing racial disparities in housing markets.\n\n**Spatial Features:**\n- **Economic Density (EconKDE) (β = -3,726.664, p < 0.001)**: The linear term shows a negative coefficient, suggesting that at low levels of economic activity, proximity to commercial areas may initially depress housing values, possibly due to noise, traffic, or other negative externalities.\n\n- **Economic Density² (EconKDE²) (β = 26,476,926, p < 0.001)**: The positive quadratic term indicates that the relationship between economic density and housing prices is U-shaped. As economic activity increases beyond a certain threshold, the benefits of proximity to amenities, employment, and urban vibrancy begin to outweigh the costs, leading to premium pricing in highly commercial areas.\n\n- **Mean 3-Nearest Neighbor Distance (β = 0.00002, p < 0.001)**: The positive coefficient suggests that properties located farther from their three nearest neighbors command slightly higher prices, possibly reflecting larger lot sizes or more exclusive locations.\n\n**Income Quantile Effects:**\n- **MHI_quantileQ2 (β = 0.136, p < 0.001)**: Properties in the second income quartile neighborhoods command approximately 14.6% higher prices than those in the lowest quartile, reflecting the premium associated with middle-income areas.\n\n- **Age-Income Interactions**: The positive interaction terms between age and higher income quantiles (Q2: β = 0.001, Q3: β = 0.003, Q4: β = 0.004) suggest that older homes retain more value in wealthier neighborhoods, likely due to better maintenance, historic preservation, or neighborhood character that offsets age-related depreciation.\n\nThe economic density relationship is particularly noteworthy—it demonstrates that Philadelphia's housing market exhibits a complex spatial pattern where moderate commercial activity may initially depress values, but high-density commercial areas (like Center City) command significant premiums, reflecting the urban amenities premium that characterizes successful city centers.\n\n### Mean Residuals By Neighborhood\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Spatial Residual Analysis (Residuals by Neighborhood)\n\n# Extract data used by model 4 and join with residuals\n# aggregate mean residual by neighborhood\n# join to neighborhood shapes and plot\nmodel_data_with_resid <- model4$model %>%\n  mutate(residual = model4$residuals)\n\nresid_sf <- phl_sales_final_sf_final %>%\n  right_join(model_data_with_resid, by = c(\"log_price\", \"log_total_livable_area\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in sf_column %in% names(g): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 3 of `x` matches multiple rows in `y`.\nℹ Row 75 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n```\n\n\n:::\n\n```{.r .cell-code}\nresid_by_neighborhood <- resid_sf %>%\n  st_drop_geometry() %>%\n  group_by(MAPNAME) %>%\n  summarize(mean_residual = mean(residual, na.rm = TRUE))\n\nphilly_residual_map <- philly_neighborhoods %>%\n  left_join(resid_by_neighborhood, by = \"MAPNAME\")\n\ntmap_mode(\"plot\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nℹ tmap mode set to \"plot\".\n```\n\n\n:::\n\n```{.r .cell-code}\nresidual_map <- tm_shape(philly_residual_map) +\n  tm_polygons(\n    col = \"mean_residual\",\n    palette = \"-RdBu\",\n    style = \"quantile\",\n    n = 5,\n    title = \"Mean Residual (Predicted - Actual)\"\n  ) +\n  tm_layout(\n    main.title = \"Residuals by Neighborhood (Model 4)\",\n    main.title.position = \"center\",\n    legend.outside = TRUE\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n[v3->v4] `tm_polygons()`: instead of `style = \"quantile\"`, use fill.scale =\n`tm_scale_intervals()`.\nℹ Migrate the argument(s) 'style', 'n', 'palette' (rename to 'values') to\n  'tm_scale_intervals(<HERE>)'[v3->v4] `tm_polygons()`: migrate the argument(s) related to the legend of the\nvisual variable `fill` namely 'title' to 'fill.legend = tm_legend(<HERE>)'[v3->v4] `tm_layout()`: use `tm_title()` instead of `tm_layout(main.title = )`\n```\n\n\n:::\n\n```{.r .cell-code}\nresidual_map\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nMultiple palettes called \"rd_bu\" found: \"brewer.rd_bu\", \"matplotlib.rd_bu\". The first one, \"brewer.rd_bu\", is returned.\n[scale] tm_polygons:() the data variable assigned to 'fill' contains positive and negative values, so midpoint is set to 0. Set 'midpoint = NA' in 'fill.scale = tm_scale_intervals(<HERE>)' to use all visual values (e.g. colors)\n[cols4all] color palettes: use palettes from the R package cols4all. Run\n`cols4all::c4a_gui()` to explore them. The old palette name \"-RdBu\" is named\n\"rd_bu\" (in long format \"brewer.rd_bu\")\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-47-1.png){width=672}\n:::\n:::\n\n# PHASE 5: Model Validation\n\n### Set up 10-fold cross-validation\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nk <- 10\nfolds <- cut(seq(1, nrow(for_model_building)), breaks = k, labels = FALSE)\n```\n:::\n\n\n### CV for Model 1\n\n::: {.cell}\n\n```{.r .cell-code}\nrmse_cv_1 <- mae_cv_1 <- r2_cv_1 <- numeric(k)\n\nfor (i in 1:k) {\n  test_indices <- which(folds == i)\n  cv_train <- for_model_building[-test_indices, ]\n  cv_test <- for_model_building[test_indices, ]\n  \n  #fit model\n  fit <- lm(log_price~log_total_livable_area+number_of_bedrooms+number_of_bathrooms+age\n            +interior_condition+quality_grade, data = cv_train)\n  preds <- predict(fit, newdata = cv_test)\n  \n  #calculate metrics\n  rmse_cv_1[i] <- sqrt(mean((cv_test$log_price - preds)^2, na.rm = TRUE))\n  mae_cv_1[i] <- mean(abs(cv_test$log_price - preds), na.rm = TRUE)\n  ss_res <- sum((cv_test$log_price - preds)^2, na.rm = TRUE)\n  ss_tot <- sum((cv_test$log_price - mean(cv_test$log_price))^2, na.rm = TRUE)\n  r2_cv_1[i] <- 1 - (ss_res / ss_tot)\n}\n\nprint(data.frame(Fold = 1:k, RMSE = round(rmse_cv_1, 4), \n                 MAE = round(mae_cv_1, 4), R2 = round(r2_cv_1, 4)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Fold   RMSE    MAE     R2\n1     1 0.6278 0.4694 0.4359\n2     2 0.6245 0.4671 0.4024\n3     3 0.6604 0.4909 0.3656\n4     4 0.6118 0.4516 0.4485\n5     5 0.6269 0.4615 0.4088\n6     6 0.7364 0.5297 0.2180\n7     7 0.6241 0.4548 0.4098\n8     8 0.5964 0.4472 0.4341\n9     9 0.5845 0.4319 0.4567\n10   10 0.6210 0.4559 0.4351\n```\n\n\n:::\n:::\n\n\n### CV for Model 2\n\n::: {.cell}\n\n```{.r .cell-code}\nrmse_cv_2 <- mae_cv_2 <- r2_cv_2 <- numeric(k)\n\nfor (i in 1:k) {\n  test_indices <- which(folds == i)\n  cv_train <- for_model_building[-test_indices, ]\n  cv_test <- for_model_building[test_indices, ]\n  \n  #fit model\n  fit <- lm(log_price~log_total_livable_area+number_of_bedrooms+number_of_bathrooms+age\n            +interior_condition+median_income+I(family_hh/total_hh)\n            +pct_bachelors+pct_vacant+pct_white+quality_grade, data = cv_train)\n  preds <- predict(fit, newdata = cv_test)\n  \n  #calculate metrics\n  rmse_cv_2[i] <- sqrt(mean((cv_test$log_price - preds)^2, na.rm = TRUE))\n  mae_cv_2[i] <- mean(abs(cv_test$log_price - preds), na.rm = TRUE)\n  ss_res <- sum((cv_test$log_price - preds)^2, na.rm = TRUE)\n  ss_tot <- sum((cv_test$log_price - mean(cv_test$log_price))^2, na.rm = TRUE)\n  r2_cv_2[i] <- 1 - (ss_res / ss_tot)\n}\n\nprint(data.frame(Fold = 1:k, RMSE = round(rmse_cv_2, 4), \n                 MAE = round(mae_cv_2, 4), R2 = round(r2_cv_2, 4)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Fold   RMSE    MAE     R2\n1     1 0.4887 0.3419 0.6638\n2     2 0.4979 0.3429 0.6251\n3     3 0.5214 0.3466 0.6086\n4     4 0.4729 0.3245 0.6749\n5     5 0.4815 0.3205 0.6549\n6     6 0.6779 0.4323 0.3466\n7     7 0.4920 0.3290 0.6375\n8     8 0.4354 0.3062 0.7013\n9     9 0.4443 0.3098 0.6895\n10   10 0.4834 0.3275 0.6616\n```\n\n\n:::\n:::\n\n\n### CV for Model 3\n\n::: {.cell}\n\n```{.r .cell-code}\nrmse_cv_3 <- mae_cv_3 <- r2_cv_3 <- numeric(k)\n\nfor (i in 1:k) {\n  test_indices <- which(folds == i)\n  cv_train <- for_model_building[-test_indices, ]\n  cv_test <- for_model_building[test_indices, ]\n  \n  #fit model\n  fit <- lm(log_price~log_total_livable_area+number_of_bedrooms+number_of_bathrooms+age\n            +interior_condition+median_income+I(family_hh/total_hh)\n            +pct_bachelors+pct_vacant+pct_white+EconKDE+I(EconKDE^2)+TreeKDE\n            +mean_3nn_dist+quality_grade, data = cv_train)\n  preds <- predict(fit, newdata = cv_test)\n  \n  #calculate metrics\n  rmse_cv_3[i] <- sqrt(mean((cv_test$log_price - preds)^2, na.rm = TRUE))\n  mae_cv_3[i] <- mean(abs(cv_test$log_price - preds), na.rm = TRUE)\n  ss_res <- sum((cv_test$log_price - preds)^2, na.rm = TRUE)\n  ss_tot <- sum((cv_test$log_price - mean(cv_test$log_price))^2, na.rm = TRUE)\n  r2_cv_3[i] <- 1 - (ss_res / ss_tot)\n}\n\nprint(data.frame(Fold = 1:k, RMSE = round(rmse_cv_3, 4), \n                 MAE = round(mae_cv_3, 4), R2 = round(r2_cv_3, 4)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Fold   RMSE    MAE     R2\n1     1 0.4824 0.3348 0.6729\n2     2 0.4905 0.3346 0.6368\n3     3 0.5133 0.3377 0.6210\n4     4 0.4658 0.3157 0.6849\n5     5 0.4756 0.3153 0.6632\n6     6 0.6785 0.4293 0.3458\n7     7 0.4855 0.3222 0.6472\n8     8 0.4271 0.2973 0.7126\n9     9 0.4358 0.2999 0.7013\n10   10 0.4784 0.3212 0.6686\n```\n\n\n:::\n:::\n\n\n### CV for Model 4\n\n::: {.cell}\n\n```{.r .cell-code}\nrmse_cv_4 <- mae_cv_4 <- r2_cv_4 <- numeric(k)\n\nfor (i in 1:k) {\n  test_indices <- which(folds == i)\n  cv_train <- for_model_building[-test_indices, ]\n  cv_test <- for_model_building[test_indices, ]\n  \n  #fit model\n  fit <- lm(log_price~log_total_livable_area+number_of_bedrooms+number_of_bathrooms+age\n            +interior_condition+median_income+I(family_hh/total_hh)\n            +pct_bachelors+pct_vacant+pct_white+EconKDE+I(EconKDE^2)+TreeKDE\n            +mean_3nn_dist+MHI_quantile*age, data = cv_train)\n  preds <- predict(fit, newdata = cv_test)\n  \n  #calculate metrics\n  rmse_cv_4[i] <- sqrt(mean((cv_test$log_price - preds)^2, na.rm = TRUE))\n  mae_cv_4[i] <- mean(abs(cv_test$log_price - preds), na.rm = TRUE)\n  ss_res <- sum((cv_test$log_price - preds)^2, na.rm = TRUE)\n  ss_tot <- sum((cv_test$log_price - mean(cv_test$log_price))^2, na.rm = TRUE)\n  r2_cv_4[i] <- 1 - (ss_res / ss_tot)\n}\n\nprint(data.frame(Fold = 1:k, RMSE = round(rmse_cv_4, 4), \n                 MAE = round(mae_cv_4, 4), R2 = round(r2_cv_4, 4)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Fold   RMSE    MAE     R2\n1     1 0.4704 0.3245 0.6868\n2     2 0.4802 0.3238 0.6504\n3     3 0.4979 0.3243 0.6382\n4     4 0.4490 0.3013 0.7030\n5     5 0.4598 0.3013 0.6816\n6     6 0.6733 0.4158 0.3526\n7     7 0.4732 0.3112 0.6613\n8     8 0.4147 0.2860 0.7288\n9     9 0.4210 0.2843 0.7194\n10   10 0.4620 0.3047 0.6864\n```\n\n\n:::\n:::\n\n\n### CV Results Summary\n\n::: {.cell}\n\n```{.r .cell-code}\ncv_summary <- data.frame(\n  Model = c(\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\"),\n  CV_RMSE = round(c(mean(rmse_cv_1), mean(rmse_cv_2), mean(rmse_cv_3), mean(rmse_cv_4)), 3),\n  CV_MAE = round(c(mean(mae_cv_1), mean(mae_cv_2), mean(mae_cv_3), mean(mae_cv_4)), 3),\n  CV_R2 = round(c(mean(r2_cv_1), mean(r2_cv_2), mean(r2_cv_3), mean(r2_cv_4)), 3)\n)\n\nstargazer(cv_summary,\n          type = \"text\",\n          title = \"10-Fold Cross-Validation Results\",\n          summary = FALSE,\n          rownames = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n10-Fold Cross-Validation Results\n============================\nModel   CV_RMSE CV_MAE CV_R2\n----------------------------\nModel 1  0.631  0.466  0.401\nModel 2  0.500  0.338  0.626\nModel 3  0.493  0.331  0.635\nModel 4  0.480  0.318  0.651\n----------------------------\n```\n\n\n:::\n:::\n\n\n### Detailed CV Results by Fold\n\n::: {.cell}\n\n```{.r .cell-code}\n# Show detailed fold-by-fold performance for model 4\ndetailed_cv <- data.frame(\n  Fold = 1:k,\n  RMSE = round(rmse_cv_4, 4),\n  MAE = round(mae_cv_4, 4),\n  R2 = round(r2_cv_4, 4)\n)\n\nprint(detailed_cv)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Fold   RMSE    MAE     R2\n1     1 0.4704 0.3245 0.6868\n2     2 0.4802 0.3238 0.6504\n3     3 0.4979 0.3243 0.6382\n4     4 0.4490 0.3013 0.7030\n5     5 0.4598 0.3013 0.6816\n6     6 0.6733 0.4158 0.3526\n7     7 0.4732 0.3112 0.6613\n8     8 0.4147 0.2860 0.7288\n9     9 0.4210 0.2843 0.7194\n10   10 0.4620 0.3047 0.6864\n```\n\n\n:::\n\n```{.r .cell-code}\n# Summary statistics across folds\ncat(\"\\nModel 4 CV Performance Summary:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nModel 4 CV Performance Summary:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"RMSE: Mean =\", round(mean(rmse_cv_4), 4), \", SD =\", round(sd(rmse_cv_4), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRMSE: Mean = 0.4801 , SD = 0.0725 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"MAE:  Mean =\", round(mean(mae_cv_4), 4), \", SD =\", round(sd(mae_cv_4), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMAE:  Mean = 0.3177 , SD = 0.0375 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"R²:   Mean =\", round(mean(r2_cv_4), 4), \", SD =\", round(sd(r2_cv_4), 4), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR²:   Mean = 0.6509 , SD = 0.1086 \n```\n\n\n:::\n:::\n\n\n### Predicted vs. Actual Plot\n\n::: {.cell}\n\n```{.r .cell-code}\n#generate predictions using model4\nfinal_predictions <- predict(model4, newdata = for_model_building)\n\n#create scatter plot\nplot(for_model_building$log_price, final_predictions,\n     xlab = \"Actual Log(Sale Price)\",\n     ylab = \"Predicted Log(Sale Price)\",\n     main = \"Predicted vs. Actual Sale Prices\",\n     pch = 16, col = rgb(0, 0, 1, 0.3))\nabline(0, 1, col = \"red\", lwd = 2, lty = 2)\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-55-1.png){width=672}\n:::\n:::\n\n### Feature Importance Analysis\n\n::: {.cell}\n\n```{.r .cell-code}\ncoefs <- coef(model4)[-1]\n\nfeature_importance <- data.frame(\n  Feature = names(coefs),\n  Coefficient = round(as.numeric(coefs), 4)\n)\n\nprint(feature_importance)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                        Feature   Coefficient\n1        log_total_livable_area        0.5092\n2            number_of_bedrooms        0.0175\n3           number_of_bathrooms        0.1512\n4                           age       -0.0042\n5            interior_condition       -0.1643\n6                 median_income        0.0000\n7         I(family_hh/total_hh)        0.0427\n8                 pct_bachelors        0.0084\n9                    pct_vacant       -0.0109\n10                    pct_white        0.0043\n11                      EconKDE    -3726.6639\n12                 I(EconKDE^2) 26476925.8415\n13                      TreeKDE      -31.9325\n14                mean_3nn_dist        0.0000\n15               MHI_quantileQ2        0.1360\n16               MHI_quantileQ3       -0.0226\n17     MHI_quantileQ4 (highest)       -0.0736\n18           age:MHI_quantileQ2        0.0014\n19           age:MHI_quantileQ3        0.0027\n20 age:MHI_quantileQ4 (highest)        0.0042\n```\n\n\n:::\n:::\n\nThe most important feature is I(EconKDE^2). It has the largest coefficient compared for all the other features. This reflects that being close to commercial activities is really important to housing prices. There is also a pattern that spatial features are important.\n\n# PHASE 6: Model Diagnostics\n\n### Diagnostic Plots for Best Model\n\n::: {.cell}\n\n```{.r .cell-code}\n#generate diagnostic plots\nplot(model4)\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-57-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-57-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-57-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-57-4.png){width=672}\n:::\n:::\n\n### Residual Plot:\nThe Residuals vs Fitted plot shows mild heteroskedasticity and a small degree of curvature, which is expected in a dataset of this size, and the model performs consistently well across most of the fitted range with only a few isolated outliers.\n\n### QQ-Plot:\nThe Q-Q plot shows slight deviation from normality in the extreme tails, which is common in large real-world housing datasets, while the majority of residuals align closely with the theoretical normal distribution, indicating that model inference remains reliable.\n\n### Cook's Distance Plot\n\n::: {.cell}\n\n```{.r .cell-code}\n#identify influential observations\ncooks_d <- cooks.distance(model4)\nplot(cooks_d, type = \"h\", main = \"Cook's Distance\",\n     ylab = \"Cook's Distance\", xlab = \"Observation\")\nabline(h = 4/nrow(for_model_building), col = \"red\", lty = 2)\n```\n\n::: {.cell-output-display}\n![](Tim_Wen_appendix_files/figure-html/unnamed-chunk-58-1.png){width=672}\n:::\n:::\n\nThe Cook’s Distance plot shows that while a few observations exert relatively higher influence on the regression model, the vast majority of cases have negligible influence, and no single data point appears to unduly distort the model’s estimated coefficients.\n\n# PHASE 7: Conclusions & Recommendations\n\nOur final model's is able to explain 64% of the variation on *logged* house prices in Philadelphia, with an average error of 48%. Our residuals mostly fall along the Q-Q plot's line and are homoscadestic (as seen in the Scale-Location plot), meaning that the residuals both fall on a normal distribution and the variance of residuals is consistent across all independent variable values. Our K-folds analysis returned an R2 of .651 (higher than the model's original .64), illustrating our model's efficacy with non-test data. The feature that matters most is the economic density around the examined housing unit, as it first has a negative relationship with housing price and then has a positive relationship.\n\nHardest neighborhoods to predict are the most affluent areas — as the social connotations of these spaces are both largely influential in housing prices as well as unquantifiable. Because of historical underdevelopment and the history of how that is tied to both race and class, housing prices are intrinsically tied to these vulnerable groups. A model that predicts housing prices is also convincing developers to focus on already well-to-do neighborhoods, whether it be when building housing or commercial centers. There are pros and cons to this, as it may protect neighborhoods from gentrification, but it could also exclude them from capital infusions and access to goods/services. Our model is limited in numerous ways, one of which is the inability to quantify power of word of mouth. For example, once the general vibe around a neighborhood — such as Fishtown — changes from working class (or from another marginalized group) to \"up and coming\" or \"hip\", future housing prices in the area may radically change. Another limitation is the non-incorporation of Philadelphia's future plans. For example, if the Roosevelt Boulevard extension was to begin construction, then our model would be unable to predict the change in housing price until the stations were built and the local impacts began.\n",
    "supporting": [
      "Tim_Wen_appendix_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}